{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты и загрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T03:23:46.326701Z",
     "iopub.status.busy": "2023-06-14T03:23:46.326076Z",
     "iopub.status.idle": "2023-06-14T03:24:10.081592Z",
     "shell.execute_reply": "2023-06-14T03:24:10.079644Z",
     "shell.execute_reply.started": "2023-06-14T03:23:46.326647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install midi2audio mido >> None\n",
    "!apt install fluidsynth >> None\n",
    "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:03.561760Z",
     "iopub.status.busy": "2023-06-14T11:12:03.560875Z",
     "iopub.status.idle": "2023-06-14T11:12:26.888192Z",
     "shell.execute_reply": "2023-06-14T11:12:26.886959Z",
     "shell.execute_reply.started": "2023-06-14T11:12:03.561714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "fluidsynth is already the newest version (2.1.1-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown music21 pretty_midi pydub >> None\n",
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:26.892055Z",
     "iopub.status.busy": "2023-06-14T11:12:26.891600Z",
     "iopub.status.idle": "2023-06-14T11:12:26.902162Z",
     "shell.execute_reply": "2023-06-14T11:12:26.900890Z",
     "shell.execute_reply.started": "2023-06-14T11:12:26.892005Z"
    },
    "id": "sqByeLu4P_8k"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as v1\n",
    "from __future__ import division\n",
    "\n",
    "import pickle\n",
    "from music21 import stream, note, duration\n",
    "import mido\n",
    "import pretty_midi\n",
    "\n",
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:26.904613Z",
     "iopub.status.busy": "2023-06-14T11:12:26.904132Z",
     "iopub.status.idle": "2023-06-14T11:12:28.839815Z",
     "shell.execute_reply": "2023-06-14T11:12:28.838139Z",
     "shell.execute_reply.started": "2023-06-14T11:12:26.904568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tonnetzDL'...\n",
      "remote: Enumerating objects: 35, done.\u001b[K\n",
      "remote: Total 35 (delta 0), reused 0 (delta 0), pack-reused 35\u001b[K\n",
      "Unpacking objects: 100% (35/35), 26.83 KiB | 1.79 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ChinghuaChuan/tonnetzDL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:28.845184Z",
     "iopub.status.busy": "2023-06-14T11:12:28.844379Z",
     "iopub.status.idle": "2023-06-14T11:12:36.564318Z",
     "shell.execute_reply": "2023-06-14T11:12:36.562906Z",
     "shell.execute_reply.started": "2023-06-14T11:12:28.845133Z"
    },
    "id": "fT7qfSZxMRZ5",
    "outputId": "86a85220-5e6a-45fe-b46f-b4f8d77aa848"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1g_sxEKwrP9Wqt3YH99eEO1aXmmAqDbui\n",
      "From (redirected): https://drive.google.com/uc?id=1g_sxEKwrP9Wqt3YH99eEO1aXmmAqDbui&confirm=t&uuid=33ed5444-d70c-449f-ac28-f8ee9e2b5d8a\n",
      "To: /kaggle/working/trained_model.zip\n",
      "100%|██████████| 37.1M/37.1M [00:00<00:00, 153MB/s] \n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/u/0/uc?id=1wIT30ESBiKRui8qCsxTTBpNeYkK-Ti90&export=download\n",
      "From (redirected): https://drive.google.com/uc?id=1wIT30ESBiKRui8qCsxTTBpNeYkK-Ti90&export=download&confirm=t&uuid=bb6e4541-9e15-4694-87b1-b29a91589aa2\n",
      "To: /kaggle/working/pickle_files.zip\n",
      "100%|██████████| 8.38M/8.38M [00:00<00:00, 98.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/pickle_files.zip'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = 'https://drive.google.com/uc?id=1g_sxEKwrP9Wqt3YH99eEO1aXmmAqDbui'\n",
    "url2 = 'https://drive.google.com/u/0/uc?id=1wIT30ESBiKRui8qCsxTTBpNeYkK-Ti90&export=download'\n",
    "output1 = '/kaggle/working/trained_model.zip'  # Specify the desired output path and filename\n",
    "output2 = '/kaggle/working/pickle_files.zip' \n",
    "gdown.download(url1, output1, quiet=False)\n",
    "gdown.download(url2, output2, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:36.566417Z",
     "iopub.status.busy": "2023-06-14T11:12:36.566068Z",
     "iopub.status.idle": "2023-06-14T11:12:44.406386Z",
     "shell.execute_reply": "2023-06-14T11:12:44.404313Z",
     "shell.execute_reply.started": "2023-06-14T11:12:36.566375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /kaggle/working/pickle_files.zip\n",
      "   creating: pickle_files/\n",
      "  inflating: pickle_files/tonnetz_template_row.txt  \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/pickle_files/\n",
      "  inflating: __MACOSX/pickle_files/._tonnetz_template_row.txt  \n",
      "  inflating: pickle_files/MuseData_train_tonnetz_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_train_tonnetz_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_valid_tonnetz_vocab_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_valid_tonnetz_vocab_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_valid_tonnetz_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_valid_tonnetz_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_valid_pianoroll_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_valid_pianoroll_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_test_tonnetz_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_test_tonnetz_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_train_pianoroll_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_train_pianoroll_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_test_pianoroll_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_test_pianoroll_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_train_tonnetz_vocab_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_train_tonnetz_vocab_p2.pickle  \n",
      "  inflating: pickle_files/MuseData_train_pianoroll_vocab_p2.pickle  \n",
      "  inflating: __MACOSX/pickle_files/._MuseData_train_pianoroll_vocab_p2.pickle  \n",
      "  inflating: __MACOSX/._pickle_files  \n",
      "Archive:  /kaggle/working/trained_model.zip\n",
      "  inflating: newSaves/checkpoint     \n",
      "  inflating: newSaves/MuseData_tonnetz_training_model_epochs27.data-00000-of-00001  \n",
      "  inflating: newSaves/MuseData_tonnetz_training_model_epochs27.index  \n",
      "  inflating: newSaves/MuseData_tonnetz_training_model_epochs27.meta  \n"
     ]
    }
   ],
   "source": [
    "!unzip /kaggle/working/pickle_files.zip\n",
    "!unzip /kaggle/working/trained_model.zip\n",
    "\n",
    "%rm /kaggle/working/pickle_files.zip\n",
    "%rm /kaggle/working/trained_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:44.409392Z",
     "iopub.status.busy": "2023-06-14T11:12:44.408946Z",
     "iopub.status.idle": "2023-06-14T11:12:45.815131Z",
     "shell.execute_reply": "2023-06-14T11:12:45.813727Z",
     "shell.execute_reply.started": "2023-06-14T11:12:44.409354Z"
    },
    "id": "3bKzHRQ5Wr6b",
    "outputId": "9d26d0df-9a3f-4ba3-cdd1-dc58a4e9c191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pickle_files\n",
      "total 326M\n",
      "drwxr-xr-x 6 root root 4.0K Jun 14 11:12 .\n",
      "drwxr-xr-x 7 root root 4.0K Jun 14 11:12 ..\n",
      "-rwxr-xr-x 1 root root  12M May 15  2018 MuseData_test_pianoroll_p2.pickle\n",
      "-rw-r--r-- 1 root root  36M May 15  2018 MuseData_test_tonnetz_p2.pickle\n",
      "-rwxr-xr-x 1 root root  44M May 15  2018 MuseData_train_pianoroll_p2.pickle\n",
      "-rwxr-xr-x 1 root root 6.9M May 15  2018 MuseData_train_pianoroll_vocab_p2.pickle\n",
      "-rw-r--r-- 1 root root 137M May 15  2018 MuseData_train_tonnetz_p2.pickle\n",
      "-rw-r--r-- 1 root root  22M May 15  2018 MuseData_train_tonnetz_vocab_p2.pickle\n",
      "-rwxr-xr-x 1 root root  15M May 15  2018 MuseData_valid_pianoroll_p2.pickle\n",
      "-rw-r--r-- 1 root root  47M May 15  2018 MuseData_valid_tonnetz_p2.pickle\n",
      "-rw-r--r-- 1 root root 9.8M May 15  2018 MuseData_valid_tonnetz_vocab_p2.pickle\n",
      "-rw-r--r-- 1 root root 3.5K Jun 14 11:12 None\n",
      "drwxrwxr-x 3 root root 4.0K May 17  2018 __MACOSX\n",
      "drwxr-xr-x 2 root root 4.0K Jun 14 11:12 newSaves\n",
      "drwxr-xr-x 2 root root 4.0K May 17  2018 pickle_files\n",
      "drwxr-xr-x 3 root root 4.0K Jun 14 11:12 tonnetzDL\n",
      "-rw-r--r-- 1 root root  878 May 17  2018 tonnetz_template_row.txt\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/pickle_files\n",
    "!ls -ahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исправление кода для совместимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:45.818480Z",
     "iopub.status.busy": "2023-06-14T11:12:45.818014Z",
     "iopub.status.idle": "2023-06-14T11:12:45.842687Z",
     "shell.execute_reply": "2023-06-14T11:12:45.841082Z",
     "shell.execute_reply.started": "2023-06-14T11:12:45.818435Z"
    },
    "id": "DQj0vVP6KVBz",
    "outputId": "d6fb3ad5-63ee-491a-99a8-728827d5403c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/tonnenz_dn_v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/tonnenz_dn_v2.py\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('vocab', type=str, help='vocabulary pickle file for tonnetz autoencoder (Required)')\n",
    "parser.add_argument('train', type=str, help='pickle file for training (Required)')\n",
    "parser.add_argument('--valid', type=str, help='pickle file for validation')\n",
    "parser.add_argument('--test', type=str, help='pickle file for testing')\n",
    "parser.add_argument('--CNNepoch', type=int, help='training epoch for CNN autoencoder')\n",
    "parser.add_argument('--LSTMepoch', type=int, help='training epoch for LSTM')\n",
    "args = parser.parse_args()\n",
    "\n",
    "vocab_file = args.vocab\n",
    "train_file = args.train\n",
    "\n",
    "if args.valid is not None:\n",
    "    valid_flag = True\n",
    "    valid_file = args.valid\n",
    "else:\n",
    "    valid_flag = False\n",
    "\n",
    "if args.test is not None:\n",
    "    test_flag = True\n",
    "    test_file = args.test\n",
    "else:\n",
    "    test_flag = False\n",
    "\n",
    "if args.CNNepoch is not None:\n",
    "    cnn_epoch = args.CNNepoch\n",
    "else:\n",
    "    cnn_epoch = 10\n",
    "\n",
    "if args.LSTMepoch is not None:\n",
    "    lstm_epoch = args.LSTMepoch\n",
    "else:\n",
    "    lstm_epoch = 27\n",
    "\n",
    "# autoencoder pre-training\n",
    "def gen_data_cnn():\n",
    "    l = pickle.load(open(vocab_file, 'rb'))\n",
    "    return l\n",
    "\n",
    "\n",
    "def gen_batch_cnn(raw_data, batch_size):\n",
    "    tonnetz_seq = raw_data\n",
    "    example = tonnetz_seq[0]\n",
    "    total_num_examples = len(tonnetz_seq)\n",
    "    num_batch = total_num_examples // batch_size\n",
    "    for i in range(num_batch - 1):\n",
    "        x = tonnetz_seq[batch_size * i:batch_size * (i + 1) - 1]\n",
    "        yield x\n",
    "\n",
    "\n",
    "def gen_epochs_cnn(n, batch_size):\n",
    "    for i in range(n):\n",
    "        yield gen_batch_cnn(gen_data_cnn(), batch_size + 1)\n",
    "\n",
    "\n",
    "# LSTM\n",
    "def gen_data(infile):\n",
    "    if 'txt' in infile:\n",
    "        f = open(infile, 'r')\n",
    "        l = [list(map(float, line.split(','))) for line in f]\n",
    "    else:\n",
    "        l = pickle.load(open(infile, 'rb'))\n",
    "    return l\n",
    "\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    tonnetz_seq = raw_data\n",
    "    total_num_examples = len(tonnetz_seq)\n",
    "    num_seqs = total_num_examples - (num_steps - 1)\n",
    "    num_batch = num_seqs // batch_size\n",
    "\n",
    "    for i in range(num_batch - 1):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for j in range(batch_size):\n",
    "            offset = (i * batch_size)\n",
    "            sequence = tonnetz_seq[offset + j: offset + j + num_steps]\n",
    "            batch_x = np.append(batch_x, sequence)\n",
    "            sequence_y = tonnetz_seq[offset + j + num_steps + 1]\n",
    "            batch_y = np.append(batch_y, sequence_y)\n",
    "        x = np.reshape(batch_x, (-1, 288))\n",
    "        y = np.reshape(batch_y, (-1, 288))\n",
    "        yield x, y\n",
    "\n",
    "\n",
    "def gen_epochs(n, batch_size, num_steps, infile):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(infile), batch_size, num_steps)\n",
    "\n",
    "\n",
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "\n",
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, filters=w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool(x, k1, k2):\n",
    "    return tf.nn.max_pool2d(input=x, ksize=[1, k1, k2, 1], strides=[1, k1, k2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# def autoencoder():\n",
    "reset_graph()\n",
    "\n",
    "# setting the parameters for both networks\n",
    "lstm_params = {}\n",
    "lstm_params['num_steps'] = 16  # number of truncated backprop steps ('n' in the discussion above)\n",
    "lstm_params['batch_size'] = 500\n",
    "lstm_params['num_classes'] = 6 * 6 * 10\n",
    "lstm_params['state_size'] = 6 * 6 * 10\n",
    "\n",
    "autoencoder_params = {}\n",
    "autoencoder_params['n_inputs'] = 12 * 24\n",
    "autoencoder_params['n_hidden1'] = 20\n",
    "autoencoder_params['n_hidden2'] = 10\n",
    "autoencoder_params['n_hidden3'] = autoencoder_params['n_hidden1']\n",
    "autoencoder_params['n_outputs'] = autoencoder_params['n_inputs']\n",
    "autoencoder_params['learning_rate'] = 1e-4\n",
    "autoencoder_params['n_epochs'] = cnn_epoch\n",
    "\n",
    "\n",
    "# building the computational graph\n",
    "def build_graph(cell_type=None,\n",
    "                num_weights_for_custom_cell=5,\n",
    "                state_size=lstm_params['state_size'],\n",
    "                num_classes=lstm_params['num_classes'],\n",
    "                batch_size=lstm_params['batch_size'],\n",
    "                num_steps=lstm_params['num_steps'],\n",
    "                num_layers=3,\n",
    "                build_with_dropout=False,\n",
    "                learning_rate=1e-4,\n",
    "                autoencoder_params=autoencoder_params):\n",
    "    initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=2.0, mode=(\"FAN_AVG\").lower(), distribution=(\"uniform\" if True else \"truncated_normal\"))\n",
    "\n",
    "    x = tf.compat.v1.placeholder(tf.float32, [None, autoencoder_params['n_inputs']],\n",
    "                       name='input_placeholder')\n",
    "    y = tf.compat.v1.placeholder(tf.float32, [None, autoencoder_params['n_inputs']], name=\"output_placeholder\")\n",
    "    dropout = tf.constant(1.0)\n",
    "    x_image = tf.reshape(x, shape=[-1, 24, 12, 1])\n",
    "\n",
    "    weight1 = tf.Variable(initializer([3, 3, 1, autoencoder_params['n_hidden1']]), name='weight1')\n",
    "    bias1 = tf.Variable(tf.zeros(autoencoder_params['n_hidden1']), name='bias1')\n",
    "    hidden1 = tf.nn.relu(conv2d(x_image, weight1) + bias1)\n",
    "    pool1 = max_pool(hidden1, 2, 2)\n",
    "\n",
    "    weight2 = tf.Variable(initializer([3, 3, autoencoder_params['n_hidden1'], autoencoder_params['n_hidden2']]),\n",
    "                          name='weight2')\n",
    "    bias2 = tf.Variable(tf.zeros(autoencoder_params['n_hidden2']), name='bias2')\n",
    "    hidden2 = tf.nn.relu(conv2d(pool1, weight2) + bias2)\n",
    "    pool2 = max_pool(hidden2, 2, 1)\n",
    "\n",
    "    # a fully connected layer for reduced-dimension CNN\n",
    "    pool2_reshaped = tf.reshape(pool2, shape=[-1, 6 * 6 * autoencoder_params['n_hidden2']])\n",
    "    final_w = tf.Variable(initializer([6 * 6 * autoencoder_params['n_hidden2'], autoencoder_params['n_outputs']]),\n",
    "                          name='final_w')\n",
    "    final_b = tf.Variable(tf.zeros(autoencoder_params['n_outputs']), name='final_b')\n",
    "    final_o = tf.matmul(pool2_reshaped, final_w) + final_b\n",
    "\n",
    "    autoencoder_outputs = final_o\n",
    "\n",
    "    loss_cnn = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=autoencoder_outputs))\n",
    "\n",
    "    optimizer_cnn = tf.compat.v1.train.AdamOptimizer(autoencoder_params['learning_rate'])\n",
    "    training_op_cnn = optimizer_cnn.minimize(loss_cnn)\n",
    "\n",
    "    # LSTM\n",
    "    fixed_w1 = tf.compat.v1.placeholder(tf.float32, [3, 3, 1, autoencoder_params['n_hidden1']], name='fixed_w1')\n",
    "    fixed_b1 = tf.compat.v1.placeholder(tf.float32, [autoencoder_params['n_hidden1']], name='fixed_b1')\n",
    "    fixed_w2 = tf.compat.v1.placeholder(tf.float32, [3, 3, autoencoder_params['n_hidden1'], autoencoder_params['n_hidden2']],\n",
    "                              name='fixed_w2')\n",
    "    fixed_b2 = tf.compat.v1.placeholder(tf.float32, [autoencoder_params['n_hidden2']], name='fixed_b2')\n",
    "    fixed_final_w = tf.compat.v1.placeholder(tf.float32,\n",
    "                                   [6 * 6 * autoencoder_params['n_hidden2'], autoencoder_params['n_outputs']],\n",
    "                                   name='fixed_final_w')\n",
    "    fixed_final_b = tf.compat.v1.placeholder(tf.float32, [autoencoder_params['n_outputs']], name='fixed_final_b')\n",
    "\n",
    "    lstm_hidden1 = tf.nn.relu(conv2d(x_image, fixed_w1) + fixed_b1)\n",
    "    lstm_pool1 = max_pool(lstm_hidden1, 2, 2)\n",
    "    lstm_hidden2 = tf.nn.relu(conv2d(lstm_pool1, fixed_w2) + fixed_b2)\n",
    "    lstm_pool2 = max_pool(lstm_hidden2, 2, 1)\n",
    "    lstm_pool2_reshaped = tf.reshape(lstm_pool2, shape=[-1, 6 * 6 * autoencoder_params['n_hidden2']])\n",
    "\n",
    "    rnn_inputs = tf.reshape(lstm_pool2_reshaped,\n",
    "                            shape=[-1, lstm_params['num_steps'], 6 * 6 * autoencoder_params['n_hidden2']])\n",
    "\n",
    "    if cell_type == 'GRU':\n",
    "        cell = tf.compat.v1.nn.rnn_cell.GRUCell(state_size)\n",
    "    elif cell_type == 'LSTM':\n",
    "        cell = tf.compat.v1.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
    "    elif cell_type == 'LN_LSTM':\n",
    "        cell = LayerNormalizedLSTMCell(state_size)\n",
    "    else:\n",
    "        cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "\n",
    "    if build_with_dropout:\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=dropout)\n",
    "\n",
    "    if cell_type == 'LSTM' or cell_type == 'LN_LSTM':\n",
    "        cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([build_rnn_cell('LSTM', state_size) for _ in range(num_layers)],\n",
    "                                           state_is_tuple=True)\n",
    "    else:\n",
    "        cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([build_rnn_cell('Basic', state_size) for _ in range(num_layers)],\n",
    "                                           state_is_tuple=True)\n",
    "\n",
    "    if build_with_dropout:\n",
    "        cell = tf.contrib.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    rnn_outputs, final_state = tf.compat.v1.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "\n",
    "\n",
    "    with tf.compat.v1.variable_scope('softmax'):\n",
    "        W = tf.compat.v1.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.compat.v1.get_variable('b', [num_classes], initializer=tf.compat.v1.constant_initializer(0.0))\n",
    "\n",
    "    rnn_outputs = rnn_outputs[:, num_steps - 1, :]\n",
    "\n",
    "    y_image = tf.reshape(y, shape=[-1, 24, 12, 1])\n",
    "    y_hidden1 = tf.nn.relu(conv2d(y_image, fixed_w1) + fixed_b1)\n",
    "    y_pool1 = max_pool(y_hidden1, 2, 2)\n",
    "    y_hidden2 = tf.nn.relu(conv2d(y_pool1, fixed_w2) + fixed_b2)\n",
    "    y_pool2 = max_pool(y_hidden2, 2, 1)\n",
    "\n",
    "    y_pool2_reshaped = tf.reshape(y_pool2, shape=[-1, 6 * 6 * autoencoder_params['n_hidden2']])\n",
    "    rnn_outputs_reshaped = tf.reshape(rnn_outputs, [-1, num_classes])\n",
    "    logits = tf.matmul(rnn_outputs_reshaped, W) + b\n",
    "\n",
    "    total_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y_pool2_reshaped))\n",
    "\n",
    "    # .............\n",
    "    # decode the output and compare it with original y\n",
    "\n",
    "    decode_logits = tf.matmul(rnn_outputs_reshaped, fixed_final_w) + fixed_final_b\n",
    "\n",
    "    tonnetz_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=decode_logits, labels=y))\n",
    "    valid_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=decode_logits, labels=y),\n",
    "                                name='valid_loss')\n",
    "    train_step = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(tonnetz_loss)\n",
    "    predictions = tf.nn.sigmoid(decode_logits, name='predictions')\n",
    "\n",
    "    return dict(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        init_state=init_state,\n",
    "        final_state=final_state,\n",
    "        total_loss=total_loss,\n",
    "        train_step=train_step,\n",
    "        tonnetz_loss=tonnetz_loss,\n",
    "        valid_loss=valid_loss,\n",
    "        preds=predictions,\n",
    "        training_op_cnn=training_op_cnn,\n",
    "        loss_cnn=loss_cnn,\n",
    "        autoencoder_outputs=autoencoder_outputs,\n",
    "        final_w=final_w,\n",
    "        weight2=weight2,\n",
    "        weight1=weight1,\n",
    "        bias1=bias1,\n",
    "        bias2=bias2,\n",
    "        final_b=final_b,\n",
    "        fixed_w1=fixed_w1,\n",
    "        fixed_b1=fixed_b1,\n",
    "        fixed_w2=fixed_w2,\n",
    "        fixed_b2=fixed_b2,\n",
    "        fixed_final_w=fixed_final_w,\n",
    "        fixed_final_b=fixed_final_b,\n",
    "        saver=tf.compat.v1.train.Saver()\n",
    "    )\n",
    "\n",
    "\n",
    "def build_rnn_cell(cell_type, state_size):\n",
    "    if cell_type == 'GRU':\n",
    "        cell = tf.compat.v1.nn.rnn_cell.GRUCell(state_size)\n",
    "    elif cell_type == 'LSTM':\n",
    "        cell = tf.compat.v1.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
    "    elif cell_type == 'LN_LSTM':\n",
    "        cell = LayerNormalizedLSTMCell(state_size)\n",
    "    else:\n",
    "        cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(state_size)\n",
    "    return cell\n",
    "\n",
    "\n",
    "def train_network(g, num_epochs, num_steps, batch_size=32, verbose=True, save=True):\n",
    "    tf.compat.v1.set_random_seed(2345)\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        with tf.device('/cpu:0'):\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "            # pre_training = True\n",
    "            if (True):\n",
    "                # pre-training\n",
    "                print(\"CNN autoencoder pre-training starts...\")\n",
    "                for idx, batch in enumerate(gen_epochs_cnn(autoencoder_params['n_epochs'], lstm_params['batch_size'])):\n",
    "                    training_losses = 0\n",
    "                    print(\"epoch\", idx)\n",
    "                    step = 0\n",
    "                    for x_batch in batch:\n",
    "                        step = step + 1\n",
    "                        feed_dict = {g['x']: x_batch}\n",
    "                        _, b_loss, batch_outputs, final_w, weight2, weight1, final_b, bias2, bias1 = sess.run(\n",
    "                            [g['training_op_cnn'],\n",
    "                             g['loss_cnn'],\n",
    "                             g['autoencoder_outputs'],\n",
    "                             g['final_w'],\n",
    "                             g['weight2'],\n",
    "                             g['weight1'],\n",
    "                             g['final_b'],\n",
    "                             g['bias2'],\n",
    "                             g['bias1']],\n",
    "                            feed_dict)\n",
    "                        #print(\"batch\", step, \", batch loss:\", b_loss)\n",
    "                        training_losses = training_losses + b_loss\n",
    "                        if idx == autoencoder_params['n_epochs'] - 1:\n",
    "                            if step == 1:\n",
    "                                final_outputs = batch_outputs\n",
    "                            else:\n",
    "                                final_outputs = np.append(final_outputs, batch_outputs, axis=0)\n",
    "\n",
    "                    training_losses = training_losses / step\n",
    "                    print(\"epoch average loss:\", training_losses)\n",
    "\n",
    "\n",
    "            # LSTM: using the input from CNN\n",
    "            training_losses = []\n",
    "            batch_losses = []\n",
    "            valid_losses = []\n",
    "            print(\"LSTM training starts...\")\n",
    "            for idx, epoch in enumerate(gen_epochs(num_epochs, batch_size, num_steps, train_file)):\n",
    "                print(\"epoch\", idx)\n",
    "                sum_tonnetz_loss = 0\n",
    "                steps = 0\n",
    "                training_state = None\n",
    "                for X, Y in epoch:\n",
    "                    steps += 1\n",
    "\n",
    "                    feed_dict = {g['x']: X, g['y']: Y, g['fixed_w1']: weight1, g['fixed_b1']: bias1,\n",
    "                                 g['fixed_w2']: weight2,\n",
    "                                 g['fixed_b2']: bias2, g['fixed_final_w']: final_w, g['fixed_final_b']: final_b}\n",
    "                    if training_state is not None:\n",
    "                        feed_dict[g['init_state']] = training_state\n",
    "                    training_state, _, tonnetz_loss, final_w, weight2, fixed_final_w = sess.run([g['final_state'],\n",
    "                                                                                                 g['train_step'],\n",
    "                                                                                                 g['tonnetz_loss'],\n",
    "                                                                                                 g['final_w'],\n",
    "                                                                                                 g['weight2'],\n",
    "                                                                                                 g['fixed_final_w']],\n",
    "                                                                                                feed_dict)\n",
    "                    # training_loss += training_loss_\n",
    "                    sum_tonnetz_loss += tonnetz_loss\n",
    "                    print(steps - 1, tonnetz_loss)\n",
    "                    batch_losses.append(tonnetz_loss)\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Average training loss for Epoch\", idx, \":\", sum_tonnetz_loss / steps)\n",
    "                training_losses.append(sum_tonnetz_loss / steps)\n",
    "\n",
    "                ##validation after each epoch:\n",
    "                if valid_flag == True:\n",
    "                    for idv, epochv in enumerate(gen_epochs(1, batch_size, num_steps, valid_file)):\n",
    "                        step = 0\n",
    "                        valid_total_loss =0\n",
    "                        for xv, yv in epochv:\n",
    "                            step += 1\n",
    "                   #        print(\"validation step:%d\" % step)\n",
    "                            feed_dict = {g['x']: xv, g['y']:yv, g['fixed_w1']:weight1, g['fixed_b1']:bias1, g['fixed_w2']:weight2, g['fixed_b2']:bias2, g['fixed_final_w']:final_w, g['fixed_final_b']:final_b}\n",
    "                            loss = sess.run(g['valid_loss'], feed_dict)\n",
    "                   #        print(\"validation loss: %f\" % loss)\n",
    "                            valid_total_loss += loss\n",
    "                        valid_losses.append(valid_total_loss/step)\n",
    "                    print(\"Average validation loss for Epoch\", idx, \":\", valid_total_loss / step)\n",
    "\n",
    "            if test_flag == True:\n",
    "                for idx, epoch in enumerate(gen_epochs(1, batch_size, num_steps, test_file)):\n",
    "                    step = 0\n",
    "                    test_total_loss = 0\n",
    "                    for x, y in epoch:\n",
    "                        step += 1\n",
    "\n",
    "                        feed_dict = {g['x']: x, g['y']: y, g['fixed_w1']: weight1, g['fixed_b1']: bias1,\n",
    "                                     g['fixed_w2']: weight2, g['fixed_b2']: bias2, g['fixed_final_w']: final_w,\n",
    "                                     g['fixed_final_b']: final_b}\n",
    "                        loss = sess.run(g['valid_loss'], feed_dict)\n",
    "                        print(\"test step:\", step, \"with loss\", loss)\n",
    "                        test_total_loss += loss\n",
    "                    print(\"Average test loss =\", test_total_loss/step)\n",
    "\n",
    "        if isinstance(save, str):\n",
    "            g['saver'].save(sess, save)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return training_losses\n",
    "\n",
    "g = build_graph(cell_type='LSTM', num_steps=lstm_params['num_steps'])\n",
    "losses = train_network(g, lstm_epoch, num_steps=lstm_params['num_steps'], batch_size=lstm_params['batch_size'], save=\"/kaggle/working/save/tonnetz_training_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:45.847078Z",
     "iopub.status.busy": "2023-06-14T11:12:45.846688Z",
     "iopub.status.idle": "2023-06-14T11:12:45.866625Z",
     "shell.execute_reply": "2023-06-14T11:12:45.864937Z",
     "shell.execute_reply.started": "2023-06-14T11:12:45.847048Z"
    },
    "id": "WnzMsA-uKqzZ",
    "outputId": "4eaf70fe-d8d2-4c71-895b-dc97a9a121ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /kaggle/working/tonnenz_generate_v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/tonnenz_generate_v2.py\n",
    "\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from numpy import genfromtxt\n",
    "import argparse\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('vocab', type=str, help='vocabulary pickle file for tonnetz autoencoder (Required)')\n",
    "parser.add_argument('test', type=str, help='pickle file for testing (Required)')\n",
    "args = parser.parse_args()\n",
    "vocab_file = args.vocab\n",
    "test_file = args.test\n",
    "\n",
    "tonnetz_template = genfromtxt('/kaggle/working/pickle_files/tonnetz_template_row.txt', delimiter=',')\n",
    "\n",
    "# autoencoder pre-training\n",
    "def gen_data_cnn():\n",
    "    l = pickle.load(open(vocab_file, 'rb'))\n",
    "    return l\n",
    "\n",
    "def gen_batch_cnn(raw_data, batch_size):\n",
    "    tonnetz_seq = raw_data\n",
    "    example = tonnetz_seq[0]\n",
    "    total_num_examples = len(tonnetz_seq)\n",
    "    num_batch = total_num_examples // batch_size\n",
    "\n",
    "    for i in range(num_batch - 1):\n",
    "        x = tonnetz_seq[batch_size * i:batch_size * (i + 1) - 1]\n",
    "        yield x\n",
    "\n",
    "\n",
    "def gen_epochs_cnn(n, batch_size):\n",
    "    for i in range(n):\n",
    "        yield gen_batch_cnn(gen_data_cnn(), batch_size+1)\n",
    "\n",
    "# LSTM\n",
    "def gen_data(infile):\n",
    "    l = pickle.load(open(infile, 'rb'))\n",
    "    return l\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    tonnetz_seq = raw_data\n",
    "    example = tonnetz_seq[0]\n",
    "    total_num_examples = len(tonnetz_seq)\n",
    "    num_seqs = total_num_examples - (num_steps - 1)\n",
    "    num_batch = num_seqs // batch_size\n",
    "    for i in range(num_batch - 1):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            offset = (i * batch_size)\n",
    "            sequence = tonnetz_seq[offset + j: offset + j + num_steps]\n",
    "            batch_x = np.append(batch_x, sequence)\n",
    "            sequence_y = tonnetz_seq[offset + j + num_steps + 1]\n",
    "            batch_y = np.append(batch_y, sequence_y)\n",
    "        x = np.reshape(batch_x, (-1, 288))\n",
    "        y = np.reshape(batch_y, (-1, 288))\n",
    "        yield x, y\n",
    "\n",
    "def gen_epochs(n, batch_size, num_steps, file):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(file), batch_size, num_steps)\n",
    "\n",
    "# setting the parameters for both networks\n",
    "lstm_params = {}\n",
    "lstm_params['num_steps'] = 16 # number of truncated backprop steps ('n' in the discussion above)\n",
    "lstm_params['batch_size'] = 500\n",
    "lstm_params['num_classes'] = 6*6*10\n",
    "lstm_params['state_size'] = 6*6*10\n",
    "\n",
    "autoencoder_params = {}\n",
    "autoencoder_params['n_inputs'] = 12 * 24\n",
    "autoencoder_params['n_hidden1'] = 20\n",
    "autoencoder_params['n_hidden2'] = 10\n",
    "autoencoder_params['n_hidden3'] = autoencoder_params['n_hidden1']\n",
    "autoencoder_params['n_outputs'] = autoencoder_params['n_inputs']\n",
    "autoencoder_params['learning_rate'] = 1e-4\n",
    "autoencoder_params['n_epochs'] = 10\n",
    "\n",
    "pred_params = {}\n",
    "pred_params['policy'] = 'majority'\n",
    "pred_params['threshold'] = 0.3\n",
    "pred_params['pred_file'] = 'Testpred_' + pred_params['policy'] + str(pred_params['threshold'])+'.pickle'\n",
    "pred_params['groundtruth_file'] = 'Testgroundtruth_' + pred_params['policy'] + str(pred_params['threshold']) + '.pickle'\n",
    "\n",
    "def generate_characters(checkpoint):\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        meta_file = checkpoint + '.meta'\n",
    "        saver = tf.compat.v1.train.import_meta_graph(meta_file)\n",
    "        saver.restore(sess, checkpoint)\n",
    "\n",
    "        print(\"Restoring variables...\")\n",
    "\n",
    "        graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "        # restore the learned weights/biases needed for autoencoder\n",
    "        x = graph.get_tensor_by_name(\"input_placeholder:0\")  # placeholder\n",
    "        y = graph.get_tensor_by_name(\"output_placeholder:0\")  # placeholder\n",
    "\n",
    "        weight1 = sess.run(graph.get_tensor_by_name(\"weight1:0\"))  # a variable\n",
    "        bias1 = sess.run(graph.get_tensor_by_name(\"bias1:0\"))\n",
    "        weight2 = sess.run(graph.get_tensor_by_name(\"weight2:0\"))\n",
    "        bias2 = sess.run(graph.get_tensor_by_name(\"bias2:0\"))\n",
    "        final_w = sess.run(graph.get_tensor_by_name(\"final_w:0\"))\n",
    "        final_b = sess.run(graph.get_tensor_by_name(\"final_b:0\"))\n",
    "        fixed_w1 = graph.get_tensor_by_name(\"fixed_w1:0\")\n",
    "        fixed_b1 = graph.get_tensor_by_name(\"fixed_b1:0\")\n",
    "        fixed_w2 = graph.get_tensor_by_name(\"fixed_w2:0\")\n",
    "        fixed_b2 = graph.get_tensor_by_name(\"fixed_b2:0\")\n",
    "        fixed_final_w = graph.get_tensor_by_name(\"fixed_final_w:0\")\n",
    "        fixed_final_b = graph.get_tensor_by_name(\"fixed_final_b:0\")\n",
    "        predictions = graph.get_tensor_by_name(\"predictions:0\")\n",
    "        valid_loss = graph.get_tensor_by_name(\"valid_loss:0\")\n",
    "\n",
    "        out_pred = []\n",
    "        out_groundtruth = []\n",
    "\n",
    "        for id, epoch in enumerate(gen_epochs(1, lstm_params['batch_size'], lstm_params['num_steps'], test_file)):\n",
    "            step = 0\n",
    "            test_total_loss = 0\n",
    "            all_predictions = np.empty(shape=[0, 288])\n",
    "\n",
    "            for xi, yi in epoch:\n",
    "                step +=1\n",
    "                feed_dict = {x: xi, y: yi, fixed_w1: weight1, fixed_b1: bias1, fixed_w2: weight2,\n",
    "                             fixed_b2: bias2, fixed_final_w: final_w, fixed_final_b: final_b}\n",
    "                pred, loss = sess.run([predictions, valid_loss], feed_dict)\n",
    "                test_total_loss += loss\n",
    "                print(\"batch \", step, \" loss = \", loss)\n",
    "                all_predictions = np.append(all_predictions, pred, axis=0)\n",
    "                # getting pitch output for the batch\n",
    "                out_pred.extend(tonnetz2note_batch(pred, pred_params['policy'], pred_params['threshold']))\n",
    "                out_groundtruth.extend(tonnetz2note_batch(yi, pred_params['policy'], pred_params['threshold']))\n",
    "\n",
    "            print('The average test loss is: ', test_total_loss/step)\n",
    "\n",
    "        np.savetxt('/kaggle/working/MuseData_tonnetz_test_predictions.txt', all_predictions)\n",
    "\n",
    "        print(\"Writing generated sequences in file:\", pred_params['pred_file'])\n",
    "        with open('/kaggle/working/'+pred_params['pred_file'], 'wb') as f:\n",
    "            pickle.dump(out_pred, f)\n",
    "\n",
    "        print(\"Writing the groundtruth for the generated sequences in file:\", pred_params['groundtruth_file'])\n",
    "        with open('/kaggle/working/'+pred_params['groundtruth_file'], 'wb') as f:\n",
    "            pickle.dump(out_groundtruth, f)\n",
    "\n",
    "#policy = 'max'\n",
    "#threshold = 0.3\n",
    "pitch_range = [6, 109] # tonnetz pitch range\n",
    "def tonnetz2note(pred, policy, threshold):\n",
    "    pitch_out_batch = []\n",
    "    count = 0\n",
    "    for frame in pred:\n",
    "        pitch = pitch_range[0]\n",
    "        pitch_out = []\n",
    "        while pitch <= pitch_range[1]:\n",
    "            index = np.where(tonnetz_template == pitch)\n",
    "            pitch_preds = []\n",
    "            for loc in index:\n",
    "                for i in loc:\n",
    "                    pitch_preds = np.append(pitch_preds, frame[i])\n",
    "\n",
    "            pitch_preds = np.array(pitch_preds)\n",
    "            out = 0\n",
    "            if policy == 'mean':\n",
    "                if np.mean(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "            elif policy == 'majority':\n",
    "                index_count = np.where(pitch_preds > threshold)\n",
    "                if len(index_count) > (len(pitch_preds)/2):\n",
    "                    out = 1\n",
    "            elif policy == 'min':\n",
    "                if min(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "            else:   # max as default\n",
    "                if max(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "\n",
    "            if out == 1:\n",
    "                pitch_out = np.append(pitch_out, pitch)\n",
    "            pitch +=1\n",
    "\n",
    "        pitch_out_batch.append(pitch_out)\n",
    "        count +=1\n",
    "    return pitch_out_batch\n",
    "\n",
    "\n",
    "def tonnetz2note_batch(pred_batch, policy, threshold):\n",
    "    pitch_out_batch = []\n",
    "    count = 0\n",
    "    for frame in pred_batch:\n",
    "        pitch = pitch_range[0]\n",
    "        pitch_out = []\n",
    "        while pitch <= pitch_range[1]:\n",
    "            index = np.where(tonnetz_template == pitch)\n",
    "            pitch_preds = []\n",
    "            for loc in index:\n",
    "                for i in loc:\n",
    "                    pitch_preds = np.append(pitch_preds, frame[i])\n",
    "\n",
    "            pitch_preds = np.array(pitch_preds)\n",
    "            out = 0\n",
    "            if policy == 'mean':\n",
    "                if np.mean(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "            elif policy == 'majority':\n",
    "                index_count = np.where(pitch_preds > threshold)\n",
    "                if len(index_count[0]) > (len(pitch_preds) / 2):\n",
    "                    out = 1\n",
    "            elif policy == 'min':\n",
    "                if min(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "            else:  # max as default\n",
    "                if max(pitch_preds) > threshold:\n",
    "                    out = 1\n",
    "\n",
    "            if out == 1:\n",
    "                pitch_out = np.append(pitch_out, pitch)\n",
    "            pitch += 1\n",
    "\n",
    "        pitch_out_batch.append(pitch_out)\n",
    "        count += 1\n",
    "    return pitch_out_batch\n",
    "\n",
    "\n",
    "print (\"Generating sequences for test file:\", test_file)\n",
    "#generate_characters(\"./save/tonnetz_training_model\")\n",
    "generate_characters(\"/kaggle/working/newSaves/MuseData_tonnetz_training_model_epochs27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:45.871519Z",
     "iopub.status.busy": "2023-06-14T11:12:45.870719Z",
     "iopub.status.idle": "2023-06-14T11:12:47.284957Z",
     "shell.execute_reply": "2023-06-14T11:12:47.283441Z",
     "shell.execute_reply.started": "2023-06-14T11:12:45.871467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/newSaves\n",
      "total 38M\n",
      "drwxr-xr-x 2 root root 4.0K Jun 14 10:25 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x 7 root root 4.0K Jun 14 11:12 \u001b[01;34m..\u001b[0m/\n",
      "-rw-r--r-- 1 root root  38M Jan 22  2018 MuseData_tonnetz_training_model_epochs27.data-00000-of-00001\n",
      "-rw-r--r-- 1 root root 1.5K Jan 22  2018 MuseData_tonnetz_training_model_epochs27.index\n",
      "-rw-r--r-- 1 root root 346K Jan 22  2018 MuseData_tonnetz_training_model_epochs27.meta\n",
      "-rw-r--r-- 1 root root  137 Jan 22  2018 checkpoint\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/newSaves\n",
    "%ls -ahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:47.288112Z",
     "iopub.status.busy": "2023-06-14T11:12:47.287660Z",
     "iopub.status.idle": "2023-06-14T11:12:48.670704Z",
     "shell.execute_reply": "2023-06-14T11:12:48.668920Z",
     "shell.execute_reply.started": "2023-06-14T11:12:47.288073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/pickle_files\n",
      "total 326M\n",
      "drwxr-xr-x 6 root root 4.0K Jun 14 11:12 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
      "drwxr-xr-x 7 root root 4.0K Jun 14 11:12 \u001b[01;34m..\u001b[0m/\n",
      "-rwxr-xr-x 1 root root  12M May 15  2018 \u001b[01;32mMuseData_test_pianoroll_p2.pickle\u001b[0m*\n",
      "-rw-r--r-- 1 root root  36M May 15  2018 MuseData_test_tonnetz_p2.pickle\n",
      "-rwxr-xr-x 1 root root  44M May 15  2018 \u001b[01;32mMuseData_train_pianoroll_p2.pickle\u001b[0m*\n",
      "-rwxr-xr-x 1 root root 6.9M May 15  2018 \u001b[01;32mMuseData_train_pianoroll_vocab_p2.pickle\u001b[0m*\n",
      "-rw-r--r-- 1 root root 137M May 15  2018 MuseData_train_tonnetz_p2.pickle\n",
      "-rw-r--r-- 1 root root  22M May 15  2018 MuseData_train_tonnetz_vocab_p2.pickle\n",
      "-rwxr-xr-x 1 root root  15M May 15  2018 \u001b[01;32mMuseData_valid_pianoroll_p2.pickle\u001b[0m*\n",
      "-rw-r--r-- 1 root root  47M May 15  2018 MuseData_valid_tonnetz_p2.pickle\n",
      "-rw-r--r-- 1 root root 9.8M May 15  2018 MuseData_valid_tonnetz_vocab_p2.pickle\n",
      "-rw-r--r-- 1 root root 3.5K Jun 14 11:12 None\n",
      "drwxrwxr-x 3 root root 4.0K May 17  2018 \u001b[01;34m__MACOSX\u001b[0m/\n",
      "drwxr-xr-x 2 root root 4.0K Jun 14 11:12 \u001b[01;34mnewSaves\u001b[0m/\n",
      "drwxr-xr-x 2 root root 4.0K May 17  2018 \u001b[01;34mpickle_files\u001b[0m/\n",
      "drwxr-xr-x 3 root root 4.0K Jun 14 11:12 \u001b[01;34mtonnetzDL\u001b[0m/\n",
      "-rw-r--r-- 1 root root  878 May 17  2018 tonnetz_template_row.txt\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/pickle_files\n",
    "%ls -ahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:12:48.676269Z",
     "iopub.status.busy": "2023-06-14T11:12:48.675793Z",
     "iopub.status.idle": "2023-06-14T11:12:48.699169Z",
     "shell.execute_reply": "2023-06-14T11:12:48.697705Z",
     "shell.execute_reply.started": "2023-06-14T11:12:48.676225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6  13   8  15  10  17  12   7  14   9  16  11]\n",
      " [ 10  17  12  19  14  21  16  11  18  13  20  15]\n",
      " [ 14  21  16  23  18  25  20  15  22  17  24  19]\n",
      " [ 18  25  20  27  22  29  24  19  26  21  28  23]\n",
      " [ 22  29  24  31  26  33  28  23  30  25  32  27]\n",
      " [ 26  33  28  35  30  37  32  27  34  29  36  31]\n",
      " [ 30  37  32  39  34  41  36  31  38  33  40  35]\n",
      " [ 34  41  36  43  38  45  40  35  42  37  44  39]\n",
      " [ 38  45  40  47  42  49  44  39  46  41  48  43]\n",
      " [ 42  49  44  51  46  53  48  43  50  45  52  47]\n",
      " [ 46  53  48  55  50  57  52  47  54  49  56  51]\n",
      " [ 50  57  52  59  54  61  56  51  58  53  60  55]\n",
      " [ 54  61  56  63  58  65  60  55  62  57  64  59]\n",
      " [ 58  65  60  67  62  69  64  59  66  61  68  63]\n",
      " [ 62  69  64  71  66  73  68  63  70  65  72  67]\n",
      " [ 66  73  68  75  70  77  72  67  74  69  76  71]\n",
      " [ 70  77  72  79  74  81  76  71  78  73  80  75]\n",
      " [ 74  81  76  83  78  85  80  75  82  77  84  79]\n",
      " [ 78  85  80  87  82  89  84  79  86  81  88  83]\n",
      " [ 82  89  84  91  86  93  88  83  90  85  92  87]\n",
      " [ 86  93  88  95  90  97  92  87  94  89  96  91]\n",
      " [ 90  97  92  99  94 101  96  91  98  93 100  95]\n",
      " [ 94 101  96 103  98 105 100  95 102  97 104  99]\n",
      " [ 98 105 100 107 102 109 104  99 106 101 108 103]]\n"
     ]
    }
   ],
   "source": [
    "templ =(np.array([6,13,8,15,10,17,12,7,14,9,16,11,10,17,12,19,14,21,16,11,18,13,20,15,\n",
    "        14,21,16,23,18,25,20,15,22,17,24,19,18,25,20,27,22,29,24,19,26,21,28,\n",
    "        23,22,29,24,31,26,33,28,23,30,25,32,27,26,33,28,35,30,37,32,27,34,29,\n",
    "        36,31,30,37,32,39,34,41,36,31,38,33,40,35,34,41,36,43,38,45,40,35,42,\n",
    "        37,44,39,38,45,40,47,42,49,44,39,46,41,48,43,42,49,44,51,46,53,48,43,\n",
    "        50,45,52,47,46,53,48,55,50,57,52,47,54,49,56,51,50,57,52,59,54,61,56,\n",
    "        51,58,53,60,55,54,61,56,63,58,65,60,55,62,57,64,59,58,65,60,67,62,69,\n",
    "        64,59,66,61,68,63,62,69,64,71,66,73,68,63,70,65,72,67,66,73,68,75,70,\n",
    "        77,72,67,74,69,76,71,70,77,72,79,74,81,76,71,78,73,80,75,74,81,76,83,\n",
    "        78,85,80,75,82,77,84,79,78,85,80,87,82,89,84,79,86,81,88,83,82,89,84,\n",
    "        91,86,93,88,83,90,85,92,87,86,93,88,95,90,97,92,87,94,89,96,91,90,97,\n",
    "        92,99,94,101,96,91,98,93,100,95,94,101,96,103,98,105,100,95,102,97,104,\n",
    "        99,98,105,100,107,102,109,104,99,106,101,108,103])).reshape(24,12)\n",
    "print(templ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T11:22:11.664592Z",
     "iopub.status.busy": "2023-06-14T11:22:11.662926Z",
     "iopub.status.idle": "2023-06-14T11:45:18.658063Z",
     "shell.execute_reply": "2023-06-14T11:45:18.656836Z",
     "shell.execute_reply.started": "2023-06-14T11:22:11.664533Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pretty_midi\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def compute_tonnetz(pitch, pitch_matrix):\n",
    "    tonnetz = np.zeros(288)\n",
    "    for i in range(pitch_matrix.shape[0]):\n",
    "        for j in range(pitch_matrix.shape[1]):\n",
    "            if pitch_matrix[i, j] == pitch:\n",
    "                tonnetz[i * pitch_matrix.shape[1] + j] = 1\n",
    "    tonnetz[tonnetz > 1] = 1  # Заменить значения больше 1 на 1\n",
    "    return tonnetz\n",
    "\n",
    "def process_midi_file(file_path, pitch_matrix):\n",
    "    midi_data = pretty_midi.PrettyMIDI(file_path)\n",
    "    dataset = []\n",
    "    unique_patterns = []\n",
    "    for note in midi_data.instruments[0].notes:\n",
    "        pitch = note.pitch\n",
    "        start_time = note.start\n",
    "        end_time = note.end\n",
    "        beat_duration = midi_data.get_beats(end_time - start_time)\n",
    "        num_time_steps = int(np.ceil(beat_duration[0]))  # Фиксированное количество интервалов (все интервалы)\n",
    "        time_step_duration = 1  # Длительность каждого интервала (1 секунда)\n",
    "        time_step_patterns = None  # Инициализация переменной\n",
    "        for step in range(num_time_steps):\n",
    "            step_start_time = start_time + step * time_step_duration\n",
    "            step_end_time = step_start_time + time_step_duration\n",
    "            notes_in_step = []\n",
    "            for note in midi_data.instruments[0].notes:\n",
    "                if step_start_time <= note.start < step_end_time:\n",
    "                    notes_in_step.append(note.pitch)\n",
    "            if notes_in_step:\n",
    "                tonnetz = np.zeros(288)\n",
    "                for pitch in notes_in_step:\n",
    "                    tonnetz += compute_tonnetz(pitch, pitch_matrix)\n",
    "                tonnetz[tonnetz > 1] = 1  # Заменить значения больше 1 на 1\n",
    "                if time_step_patterns is None:  # Проверка на инициализацию\n",
    "                    time_step_patterns = []\n",
    "                time_step_patterns.append(tonnetz.tolist())\n",
    "                unique_patterns.append(tonnetz.tolist())\n",
    "        if time_step_patterns is not None:  # Проверка на инициализацию\n",
    "            dataset.extend(time_step_patterns)\n",
    "\n",
    "    return dataset, unique_patterns\n",
    "\n",
    "# Pattern tonnetz\n",
    "pitch_matrix = templ\n",
    "\n",
    "folder_path = \"/kaggle/input/jazzset/jazztrimmedfortime\"\n",
    "\n",
    "# Получение списка файлов\n",
    "midi_files = os.listdir(folder_path)\n",
    "\n",
    "# Разделение на тренировочный, валидационный и тестовый наборы данных\n",
    "train_files, temp_files = train_test_split(midi_files, test_size=0.4, random_state=42)\n",
    "valid_files, test_files = train_test_split(temp_files, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataset = []\n",
    "train_vocab = []\n",
    "for file_name in train_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    dataset, vocab = process_midi_file(file_path, pitch_matrix)\n",
    "    train_dataset.extend(dataset)\n",
    "    train_vocab.extend(vocab)\n",
    "\n",
    "valid_dataset = []\n",
    "valid_vocab = []\n",
    "for file_name in valid_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    dataset, vocab = process_midi_file(file_path, pitch_matrix)\n",
    "    valid_dataset.extend(dataset)\n",
    "    valid_vocab.extend(vocab)\n",
    "\n",
    "test_dataset = []\n",
    "test_vocab = []\n",
    "for file_name in test_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    dataset, vocab = process_midi_file(file_path, pitch_matrix)\n",
    "    test_dataset.extend(dataset)\n",
    "    test_vocab.extend(vocab)\n",
    "\n",
    "# Сохранение тренировочных данных в файлы\n",
    "train_data_path = \"/kaggle/working/train_dataset.pickle\"\n",
    "with open(train_data_path, \"wb\") as f:\n",
    "    pickle.dump(train_dataset, f)\n",
    "\n",
    "train_vocab_path = \"/kaggle/working/train_vocab.pickle\"\n",
    "with open(train_vocab_path, \"wb\") as f:\n",
    "    pickle.dump(train_vocab, f)\n",
    "\n",
    "# Сохранение валидационных данных в файлы\n",
    "valid_data_path = \"/kaggle/working/valid_dataset.pickle\"\n",
    "with open(valid_data_path, \"wb\") as f:\n",
    "    pickle.dump(valid_dataset, f)\n",
    "\n",
    "valid_vocab_path = \"/kaggle/working/valid_vocab.pickle\"\n",
    "with open(valid_vocab_path, \"wb\") as f:\n",
    "    pickle.dump(valid_vocab, f)\n",
    "\n",
    "# Сохранение тестовых данных в файлы\n",
    "test_data_path = \"/kaggle/working/test_dataset.pickle\"\n",
    "with open(test_data_path, \"wb\") as f:\n",
    "    pickle.dump(test_dataset, f)\n",
    "\n",
    "test_vocab_path = \"/kaggle/working/test_vocab.pickle\"\n",
    "with open(test_vocab_path, \"wb\") as f:\n",
    "    pickle.dump(test_vocab, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T14:57:10.055082Z",
     "iopub.status.busy": "2023-06-14T14:57:10.054544Z",
     "iopub.status.idle": "2023-06-14T14:57:22.184954Z",
     "shell.execute_reply": "2023-06-14T14:57:22.183331Z",
     "shell.execute_reply.started": "2023-06-14T14:57:10.055041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "66303 190555\n",
      "288 288\n",
      "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Загрузка сгенерированных музыкальных последовательностей из файла\n",
    "with open('/kaggle/working/test_vocab.pickle', 'rb') as f:\n",
    "    tvocab = pickle.load(f)\n",
    "\n",
    "# Загрузка сгенерированных музыкальных последовательностей из файла\n",
    "with open('/kaggle/working/train_dataset.pickle', 'rb') as f:\n",
    "    sequences = pickle.load(f)  # Взять все интервалы\n",
    "\n",
    "print(tvocab[0] == sequences[0])\n",
    "print(len(tvocab), len(sequences))\n",
    "print(len(tvocab[0]), len(sequences[1]))\n",
    "\n",
    "print(sequences[:2])\n",
    "print(np.count_nonzero(tvocab[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T12:43:18.372116Z",
     "iopub.status.busy": "2023-06-14T12:43:18.371423Z",
     "iopub.status.idle": "2023-06-14T13:29:55.759262Z",
     "shell.execute_reply": "2023-06-14T13:29:55.757344Z",
     "shell.execute_reply.started": "2023-06-14T12:43:18.372046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "/kaggle/working/tonnenz_dn_v2.py:202: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
      "/kaggle/working/tonnenz_dn_v2.py:287: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)\n",
      "CNN autoencoder pre-training starts...\n",
      "epoch 0\n",
      "epoch average loss: 0.3558186479797464\n",
      "epoch 1\n",
      "epoch average loss: 0.21777173326323718\n",
      "epoch 2\n",
      "epoch average loss: 0.20494733255425354\n",
      "epoch 3\n",
      "epoch average loss: 0.19563076053414308\n",
      "epoch 4\n",
      "epoch average loss: 0.18714883699423404\n",
      "epoch 5\n",
      "epoch average loss: 0.17875878273025353\n",
      "epoch 6\n",
      "epoch average loss: 0.17030079476043858\n",
      "epoch 7\n",
      "epoch average loss: 0.1618559512464541\n",
      "epoch 8\n",
      "epoch average loss: 0.15359713620749502\n",
      "epoch 9\n",
      "epoch average loss: 0.14570264966475302\n",
      "epoch 10\n",
      "epoch average loss: 0.1382610230143907\n",
      "epoch 11\n",
      "epoch average loss: 0.13123591246186586\n",
      "epoch 12\n",
      "epoch average loss: 0.12451869736875268\n",
      "epoch 13\n",
      "epoch average loss: 0.11801240728838777\n",
      "epoch 14\n",
      "epoch average loss: 0.1116548828623383\n",
      "epoch 15\n",
      "epoch average loss: 0.10541994725218863\n",
      "epoch 16\n",
      "epoch average loss: 0.09931658238840921\n",
      "epoch 17\n",
      "epoch average loss: 0.0933829235173467\n",
      "epoch 18\n",
      "epoch average loss: 0.08768776072911663\n",
      "epoch 19\n",
      "epoch average loss: 0.08228885230060302\n",
      "epoch 20\n",
      "epoch average loss: 0.07722566455189817\n",
      "epoch 21\n",
      "epoch average loss: 0.07252326356075055\n",
      "epoch 22\n",
      "epoch average loss: 0.0681739667858093\n",
      "epoch 23\n",
      "epoch average loss: 0.0641775215413215\n",
      "epoch 24\n",
      "epoch average loss: 0.06051257871445219\n",
      "epoch 25\n",
      "epoch average loss: 0.05715044107691122\n",
      "epoch 26\n",
      "epoch average loss: 0.05406370764416409\n",
      "LSTM training starts...\n",
      "epoch 0\n",
      "0 0.68702793\n",
      "1 0.61666447\n",
      "2 0.554084\n",
      "3 0.5147294\n",
      "4 0.47198254\n",
      "5 0.44405562\n",
      "6 0.42310748\n",
      "7 0.39922476\n",
      "8 0.37227193\n",
      "9 0.36153236\n",
      "10 0.34578344\n",
      "11 0.3357403\n",
      "12 0.3567425\n",
      "13 0.31937712\n",
      "14 0.3057754\n",
      "15 0.2961225\n",
      "16 0.29194346\n",
      "17 0.27767566\n",
      "18 0.27172977\n",
      "19 0.26036015\n",
      "20 0.22837847\n",
      "21 0.23362492\n",
      "22 0.26604986\n",
      "23 0.3172512\n",
      "24 0.34209898\n",
      "25 0.2969571\n",
      "26 0.3209687\n",
      "27 0.3077531\n",
      "28 0.30698436\n",
      "29 0.2845897\n",
      "30 0.29940277\n",
      "31 0.25232422\n",
      "32 0.20544508\n",
      "33 0.18933724\n",
      "34 0.24193195\n",
      "35 0.25599486\n",
      "36 0.26679224\n",
      "37 0.26822993\n",
      "38 0.25361684\n",
      "39 0.260698\n",
      "40 0.24400473\n",
      "41 0.23396055\n",
      "42 0.23339003\n",
      "43 0.27244082\n",
      "44 0.255937\n",
      "45 0.2207979\n",
      "46 0.24338216\n",
      "47 0.2518845\n",
      "48 0.2534937\n",
      "49 0.24853787\n",
      "50 0.2628872\n",
      "51 0.27307463\n",
      "52 0.2851437\n",
      "53 0.24981365\n",
      "54 0.22089128\n",
      "55 0.23351076\n",
      "56 0.20730059\n",
      "57 0.2155124\n",
      "58 0.20946254\n",
      "59 0.20856427\n",
      "60 0.20765913\n",
      "61 0.20430504\n",
      "62 0.24557422\n",
      "63 0.30492005\n",
      "64 0.18232943\n",
      "65 0.17467967\n",
      "66 0.1792698\n",
      "67 0.23712951\n",
      "68 0.25341663\n",
      "69 0.25206354\n",
      "70 0.24769862\n",
      "71 0.23675933\n",
      "72 0.25238097\n",
      "73 0.23877202\n",
      "74 0.21709083\n",
      "75 0.22816512\n",
      "76 0.24061038\n",
      "77 0.2429994\n",
      "78 0.25400278\n",
      "79 0.22835411\n",
      "80 0.23537408\n",
      "81 0.22214314\n",
      "82 0.28186128\n",
      "83 0.2789189\n",
      "84 0.24939534\n",
      "85 0.24978952\n",
      "86 0.23282826\n",
      "87 0.2128632\n",
      "88 0.20008415\n",
      "89 0.21318276\n",
      "90 0.20964247\n",
      "91 0.18782233\n",
      "92 0.18210924\n",
      "93 0.17294672\n",
      "94 0.18423833\n",
      "95 0.19913016\n",
      "96 0.28757077\n",
      "97 0.26066923\n",
      "98 0.2910316\n",
      "99 0.2847821\n",
      "100 0.2999815\n",
      "101 0.31272134\n",
      "102 0.284696\n",
      "103 0.2548818\n",
      "104 0.26035687\n",
      "105 0.2570439\n",
      "106 0.22484426\n",
      "107 0.23743199\n",
      "108 0.23850287\n",
      "109 0.24141097\n",
      "110 0.25798428\n",
      "111 0.2278285\n",
      "112 0.25317666\n",
      "113 0.22937652\n",
      "114 0.22236052\n",
      "115 0.23394048\n",
      "116 0.24263173\n",
      "117 0.21870288\n",
      "118 0.2134431\n",
      "119 0.23422043\n",
      "120 0.23623776\n",
      "121 0.29505798\n",
      "122 0.2571064\n",
      "123 0.22564599\n",
      "124 0.2569624\n",
      "125 0.21995914\n",
      "126 0.21447353\n",
      "127 0.19792318\n",
      "128 0.20184566\n",
      "129 0.1967256\n",
      "130 0.196256\n",
      "131 0.20550814\n",
      "132 0.20720892\n",
      "133 0.22194403\n",
      "134 0.24606739\n",
      "135 0.21997483\n",
      "136 0.21801326\n",
      "137 0.18576711\n",
      "138 0.17801546\n",
      "139 0.20108691\n",
      "140 0.22943354\n",
      "141 0.20018496\n",
      "142 0.22348863\n",
      "143 0.21860346\n",
      "144 0.18945448\n",
      "145 0.17796552\n",
      "146 0.23816651\n",
      "147 0.26315504\n",
      "148 0.24284597\n",
      "149 0.23027553\n",
      "150 0.25824246\n",
      "151 0.228634\n",
      "152 0.2644739\n",
      "153 0.2614897\n",
      "154 0.24121745\n",
      "155 0.23758607\n",
      "156 0.27483445\n",
      "157 0.2691422\n",
      "158 0.2287319\n",
      "159 0.2235674\n",
      "160 0.2179122\n",
      "161 0.19956933\n",
      "162 0.19547392\n",
      "163 0.20787933\n",
      "164 0.19321944\n",
      "165 0.2706394\n",
      "166 0.30677167\n",
      "167 0.30908144\n",
      "168 0.32129595\n",
      "169 0.26702842\n",
      "170 0.34016415\n",
      "171 0.27033243\n",
      "172 0.28761402\n",
      "173 0.36417758\n",
      "174 0.31993088\n",
      "175 0.3309802\n",
      "176 0.30202103\n",
      "177 0.40397885\n",
      "178 0.3207825\n",
      "179 0.32488847\n",
      "180 0.31740806\n",
      "181 0.2973075\n",
      "182 0.3175413\n",
      "183 0.28986904\n",
      "184 0.3163763\n",
      "185 0.27169403\n",
      "186 0.19809982\n",
      "187 0.23511323\n",
      "188 0.26221868\n",
      "189 0.25139797\n",
      "190 0.2396339\n",
      "191 0.23616248\n",
      "192 0.18303128\n",
      "193 0.20988679\n",
      "194 0.21230829\n",
      "195 0.2146446\n",
      "196 0.22828938\n",
      "197 0.22633034\n",
      "198 0.2585236\n",
      "199 0.21555436\n",
      "200 0.20190977\n",
      "201 0.19949907\n",
      "202 0.19101259\n",
      "203 0.19871332\n",
      "204 0.22801495\n",
      "205 0.21636288\n",
      "206 0.21128836\n",
      "207 0.20280334\n",
      "208 0.22169684\n",
      "209 0.21990854\n",
      "210 0.22895323\n",
      "211 0.2225274\n",
      "212 0.23222\n",
      "213 0.22632614\n",
      "214 0.18441235\n",
      "215 0.21883792\n",
      "216 0.22633705\n",
      "217 0.24216016\n",
      "218 0.2627007\n",
      "219 0.23027344\n",
      "220 0.20052554\n",
      "221 0.19927931\n",
      "222 0.20968188\n",
      "223 0.19575708\n",
      "224 0.20026083\n",
      "225 0.20967251\n",
      "226 0.18902\n",
      "227 0.2168482\n",
      "228 0.20455116\n",
      "229 0.17235067\n",
      "230 0.1961583\n",
      "231 0.1979553\n",
      "232 0.20196852\n",
      "233 0.19231814\n",
      "234 0.21989319\n",
      "235 0.2404357\n",
      "236 0.25513962\n",
      "237 0.26335126\n",
      "238 0.23270307\n",
      "239 0.24551867\n",
      "240 0.2991656\n",
      "241 0.32202363\n",
      "242 0.38964918\n",
      "243 0.3570267\n",
      "244 0.22603953\n",
      "245 0.25889963\n",
      "246 0.29472595\n",
      "247 0.25772172\n",
      "248 0.24080881\n",
      "249 0.23584718\n",
      "250 0.27307302\n",
      "251 0.2467908\n",
      "252 0.24690089\n",
      "253 0.26200786\n",
      "254 0.2573996\n",
      "255 0.2532415\n",
      "256 0.20935489\n",
      "257 0.19973385\n",
      "258 0.21192653\n",
      "259 0.21465419\n",
      "260 0.21943086\n",
      "261 0.21839067\n",
      "262 0.22343744\n",
      "263 0.21425249\n",
      "264 0.20867175\n",
      "265 0.20890982\n",
      "266 0.20529935\n",
      "267 0.21065728\n",
      "268 0.23106052\n",
      "269 0.24127865\n",
      "270 0.23970082\n",
      "271 0.24206556\n",
      "272 0.23122814\n",
      "273 0.21911865\n",
      "274 0.17672114\n",
      "275 0.20861895\n",
      "276 0.17998074\n",
      "277 0.19561185\n",
      "278 0.19071619\n",
      "279 0.1853273\n",
      "280 0.16674705\n",
      "281 0.2038703\n",
      "282 0.24616976\n",
      "283 0.22316962\n",
      "284 0.17087646\n",
      "285 0.1944781\n",
      "286 0.20600581\n",
      "287 0.19193543\n",
      "288 0.19247678\n",
      "289 0.19859232\n",
      "290 0.19551665\n",
      "291 0.19109705\n",
      "292 0.22575809\n",
      "293 0.20034361\n",
      "294 0.20658837\n",
      "295 0.17438376\n",
      "296 0.20357597\n",
      "297 0.20337337\n",
      "298 0.23978743\n",
      "299 0.21791534\n",
      "300 0.20595795\n",
      "301 0.20339459\n",
      "302 0.20536907\n",
      "303 0.19921878\n",
      "304 0.17520298\n",
      "305 0.20843118\n",
      "306 0.19883975\n",
      "307 0.21152847\n",
      "308 0.26155487\n",
      "309 0.35930687\n",
      "310 0.30840343\n",
      "311 0.28250825\n",
      "312 0.22622724\n",
      "313 0.15930852\n",
      "314 0.18773545\n",
      "315 0.17301197\n",
      "316 0.19359495\n",
      "317 0.1606527\n",
      "318 0.2079552\n",
      "319 0.1976807\n",
      "320 0.16313942\n",
      "321 0.16020177\n",
      "322 0.24359947\n",
      "323 0.25642017\n",
      "324 0.26050276\n",
      "325 0.23611407\n",
      "326 0.2594913\n",
      "327 0.26851878\n",
      "328 0.24894878\n",
      "329 0.29346335\n",
      "330 0.25791866\n",
      "331 0.25871116\n",
      "332 0.23382999\n",
      "333 0.22231875\n",
      "334 0.2047003\n",
      "335 0.19685024\n",
      "336 0.20518069\n",
      "337 0.2340434\n",
      "338 0.20904322\n",
      "339 0.20261495\n",
      "340 0.19918096\n",
      "341 0.20909792\n",
      "342 0.19094372\n",
      "343 0.1836378\n",
      "344 0.17128849\n",
      "345 0.17341119\n",
      "346 0.18552852\n",
      "347 0.19473244\n",
      "348 0.2133642\n",
      "349 0.17543192\n",
      "350 0.1908982\n",
      "351 0.18930696\n",
      "352 0.1749297\n",
      "353 0.18654571\n",
      "354 0.1973704\n",
      "355 0.19808722\n",
      "356 0.20981255\n",
      "357 0.23398812\n",
      "358 0.2464223\n",
      "359 0.3009589\n",
      "360 0.2792941\n",
      "361 0.22894195\n",
      "362 0.19958569\n",
      "363 0.17737994\n",
      "364 0.19248931\n",
      "365 0.18899007\n",
      "366 0.21566144\n",
      "367 0.19872448\n",
      "368 0.17030291\n",
      "369 0.18165039\n",
      "370 0.20025624\n",
      "371 0.24194208\n",
      "372 0.25254574\n",
      "373 0.27593318\n",
      "374 0.23103431\n",
      "375 0.24709001\n",
      "376 0.24611285\n",
      "377 0.23801541\n",
      "378 0.2581109\n",
      "379 0.24837239\n",
      "Average training loss for Epoch 0 : 0.24148736486309452\n",
      "Average validation loss for Epoch 0 : 0.22432547550004228\n"
     ]
    }
   ],
   "source": [
    "# Код для обучения нейросети\n",
    "\n",
    "!python /kaggle/working/tonnenz_dn_v2.py \\\n",
    "    --valid /kaggle/working/valid_dataset.pickle \\\n",
    "    --CNNepoch 27 --LSTMepoch 1 \\\n",
    "    /kaggle/working/train_dataset.pickle \\\n",
    "    /kaggle/working/train_vocab.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:17:24.823094Z",
     "iopub.status.busy": "2023-06-14T15:17:24.822529Z",
     "iopub.status.idle": "2023-06-14T15:33:27.501238Z",
     "shell.execute_reply": "2023-06-14T15:33:27.499447Z",
     "shell.execute_reply.started": "2023-06-14T15:17:24.823057Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "Generating sequences for test file: /kaggle/working/test_dataset.pickle\n",
      "Restoring variables...\n",
      "batch  1  loss =  0.21939966\n",
      "batch  2  loss =  0.22368756\n",
      "batch  3  loss =  0.25957286\n",
      "batch  4  loss =  0.24082422\n",
      "batch  5  loss =  0.25776\n",
      "batch  6  loss =  0.20437944\n",
      "batch  7  loss =  0.17594273\n",
      "batch  8  loss =  0.1989715\n",
      "batch  9  loss =  0.2333549\n",
      "batch  10  loss =  0.19555654\n",
      "batch  11  loss =  0.19235237\n",
      "batch  12  loss =  0.18139999\n",
      "batch  13  loss =  0.19949387\n",
      "batch  14  loss =  0.26230577\n",
      "batch  15  loss =  0.18488628\n",
      "batch  16  loss =  0.21968003\n",
      "batch  17  loss =  0.18923496\n",
      "batch  18  loss =  0.18560654\n",
      "batch  19  loss =  0.21217002\n",
      "batch  20  loss =  0.23437612\n",
      "batch  21  loss =  0.32337207\n",
      "batch  22  loss =  0.27467117\n",
      "batch  23  loss =  0.22601192\n",
      "batch  24  loss =  0.20243698\n",
      "batch  25  loss =  0.20162359\n",
      "batch  26  loss =  0.1896232\n",
      "batch  27  loss =  0.18599355\n",
      "batch  28  loss =  0.1805896\n",
      "batch  29  loss =  0.19112344\n",
      "batch  30  loss =  0.1902231\n",
      "batch  31  loss =  0.1844458\n",
      "batch  32  loss =  0.18260449\n",
      "batch  33  loss =  0.18533544\n",
      "batch  34  loss =  0.1808467\n",
      "batch  35  loss =  0.17907761\n",
      "batch  36  loss =  0.1976132\n",
      "batch  37  loss =  0.19779234\n",
      "batch  38  loss =  0.22406437\n",
      "batch  39  loss =  0.24852838\n",
      "batch  40  loss =  0.19107486\n",
      "batch  41  loss =  0.15897824\n",
      "batch  42  loss =  0.14336622\n",
      "batch  43  loss =  0.16911735\n",
      "batch  44  loss =  0.20583396\n",
      "batch  45  loss =  0.2531159\n",
      "batch  46  loss =  0.19989201\n",
      "batch  47  loss =  0.15843308\n",
      "batch  48  loss =  0.20422255\n",
      "batch  49  loss =  0.22163787\n",
      "batch  50  loss =  0.16889013\n",
      "batch  51  loss =  0.14381345\n",
      "batch  52  loss =  0.13894919\n",
      "batch  53  loss =  0.14633983\n",
      "batch  54  loss =  0.17774296\n",
      "batch  55  loss =  0.21481673\n",
      "batch  56  loss =  0.22517647\n",
      "batch  57  loss =  0.12807712\n",
      "batch  58  loss =  0.07395272\n",
      "batch  59  loss =  0.08228185\n",
      "batch  60  loss =  0.16075046\n",
      "batch  61  loss =  0.14790393\n",
      "batch  62  loss =  0.15476733\n",
      "batch  63  loss =  0.15951392\n",
      "batch  64  loss =  0.1693814\n",
      "batch  65  loss =  0.19630641\n",
      "batch  66  loss =  0.22236882\n",
      "batch  67  loss =  0.21217942\n",
      "batch  68  loss =  0.19136253\n",
      "batch  69  loss =  0.21653563\n",
      "batch  70  loss =  0.23689605\n",
      "batch  71  loss =  0.22660914\n",
      "batch  72  loss =  0.23743409\n",
      "batch  73  loss =  0.24664985\n",
      "batch  74  loss =  0.26601768\n",
      "batch  75  loss =  0.23268452\n",
      "batch  76  loss =  0.2596651\n",
      "batch  77  loss =  0.25036424\n",
      "batch  78  loss =  0.19886535\n",
      "batch  79  loss =  0.16200796\n",
      "batch  80  loss =  0.20000161\n",
      "batch  81  loss =  0.17879392\n",
      "batch  82  loss =  0.26353666\n",
      "batch  83  loss =  0.20411915\n",
      "batch  84  loss =  0.16762845\n",
      "batch  85  loss =  0.19311288\n",
      "batch  86  loss =  0.15789518\n",
      "batch  87  loss =  0.14991498\n",
      "batch  88  loss =  0.1809597\n",
      "batch  89  loss =  0.15455014\n",
      "batch  90  loss =  0.12986143\n",
      "batch  91  loss =  0.11305037\n",
      "batch  92  loss =  0.13851716\n",
      "batch  93  loss =  0.1398369\n",
      "batch  94  loss =  0.14876914\n",
      "batch  95  loss =  0.16818263\n",
      "batch  96  loss =  0.16672592\n",
      "batch  97  loss =  0.14433186\n",
      "batch  98  loss =  0.16748041\n",
      "batch  99  loss =  0.17200564\n",
      "batch  100  loss =  0.14476681\n",
      "batch  101  loss =  0.186581\n",
      "batch  102  loss =  0.20815647\n",
      "batch  103  loss =  0.20501792\n",
      "batch  104  loss =  0.21645795\n",
      "batch  105  loss =  0.2022495\n",
      "batch  106  loss =  0.2290415\n",
      "batch  107  loss =  0.25406265\n",
      "batch  108  loss =  0.23469043\n",
      "batch  109  loss =  0.29338527\n",
      "batch  110  loss =  0.25394896\n",
      "batch  111  loss =  0.25851595\n",
      "batch  112  loss =  0.21410197\n",
      "batch  113  loss =  0.1487934\n",
      "batch  114  loss =  0.15518948\n",
      "batch  115  loss =  0.14545195\n",
      "batch  116  loss =  0.16736047\n",
      "batch  117  loss =  0.19349404\n",
      "batch  118  loss =  0.18875039\n",
      "batch  119  loss =  0.20206809\n",
      "batch  120  loss =  0.20242575\n",
      "batch  121  loss =  0.22543015\n",
      "batch  122  loss =  0.20351434\n",
      "batch  123  loss =  0.26877436\n",
      "batch  124  loss =  0.21014087\n",
      "batch  125  loss =  0.18276766\n",
      "batch  126  loss =  0.17156936\n",
      "batch  127  loss =  0.15824872\n",
      "batch  128  loss =  0.17995141\n",
      "batch  129  loss =  0.16554743\n",
      "batch  130  loss =  0.16671574\n",
      "batch  131  loss =  0.15008079\n",
      "The average test loss is:  0.1946368967645041\n",
      "Writing generated sequences in file: Testpred_majority0.3.pickle\n",
      "Writing the groundtruth for the generated sequences in file: Testgroundtruth_majority0.3.pickle\n"
     ]
    }
   ],
   "source": [
    "# генерация\n",
    "\n",
    "!python /kaggle/working/tonnenz_generate_v2.py \\\n",
    "  /kaggle/working/test_vocab.pickle \\\n",
    "  /kaggle/working/test_dataset.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:34:27.527568Z",
     "iopub.status.busy": "2023-06-14T15:34:27.526001Z",
     "iopub.status.idle": "2023-06-14T15:34:28.047207Z",
     "shell.execute_reply": "2023-06-14T15:34:28.045882Z",
     "shell.execute_reply.started": "2023-06-14T15:34:27.527491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([57., 60., 62., 64., 69., 72., 76., 81.]),\n",
       " array([60., 62., 64., 69., 72., 76., 81.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 76., 81.]),\n",
       " array([64., 69., 72., 76., 81.]),\n",
       " array([64., 69., 72., 81.]),\n",
       " array([64., 69., 81.]),\n",
       " array([64., 69.]),\n",
       " array([64., 69.]),\n",
       " array([64., 69.]),\n",
       " array([64., 69.]),\n",
       " array([64., 69.]),\n",
       " array([64., 69.]),\n",
       " array([62., 64., 69.]),\n",
       " array([69., 81.]),\n",
       " array([64., 69., 76., 81.]),\n",
       " array([64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 74., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 74., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84., 86.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84., 86.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84., 86.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 81., 84., 86.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 67., 72., 74., 76., 79., 81., 84., 88., 89.]),\n",
       " array([60., 67., 72., 79., 84., 88., 89.]),\n",
       " array([60., 64., 67., 72., 79., 84., 88.]),\n",
       " array([60., 64., 67., 72., 79.]),\n",
       " array([60., 67., 72., 79.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 64., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79.]),\n",
       " array([60., 67., 72., 79.]),\n",
       " array([63., 67., 79.]),\n",
       " array([63., 67., 79.]),\n",
       " array([62., 63., 67.]),\n",
       " array([62., 63., 67.]),\n",
       " array([62., 63.]),\n",
       " array([60., 62.]),\n",
       " array([60., 62., 65.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 62., 65.]),\n",
       " array([72., 79.]),\n",
       " array([72., 74., 77.]),\n",
       " array([72., 74., 77.]),\n",
       " array([60., 65., 72., 74., 77., 79.]),\n",
       " array([72., 74., 77., 79.]),\n",
       " array([72., 74., 76., 77.]),\n",
       " array([72., 76., 77.]),\n",
       " array([60., 65., 72., 76., 77.]),\n",
       " array([60., 65., 72., 74., 76., 77.]),\n",
       " array([60., 65., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 65., 67., 69., 72., 74., 76., 77.]),\n",
       " array([60., 62., 65., 67., 69., 72., 74., 76., 77.]),\n",
       " array([60., 62., 65., 67., 69., 72., 74., 77.]),\n",
       " array([60., 64., 65., 67., 69., 72., 76., 79.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72.]),\n",
       " array([60., 62., 64., 65., 67., 69.]),\n",
       " array([60., 64., 69., 72.]),\n",
       " array([60., 62., 69., 72.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([57., 60., 62., 64., 67., 69., 72.]),\n",
       " array([57., 59., 60., 62., 64., 67., 69., 71., 72., 74.]),\n",
       " array([57., 60., 62., 64., 67., 69., 71., 72., 74., 76.]),\n",
       " array([57., 60., 62., 64., 67., 69., 71., 72., 74., 76.]),\n",
       " array([57., 60., 62., 64., 67., 69., 71., 72., 74., 76.]),\n",
       " array([67., 69., 72., 74., 76., 79.]),\n",
       " array([60., 67., 69., 72., 74., 76.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76.]),\n",
       " array([62., 67., 69., 72., 74., 76.]),\n",
       " array([62., 67., 69., 72., 74., 76.]),\n",
       " array([62., 67., 69., 72., 74., 76.]),\n",
       " array([62., 67., 69., 72., 74., 76.]),\n",
       " array([62., 65., 67., 69., 72., 74., 76.]),\n",
       " array([62., 65., 69., 72., 74., 76.]),\n",
       " array([60., 62., 65., 67., 69., 72., 74.]),\n",
       " array([60., 62., 65., 67., 69., 72.]),\n",
       " array([60., 62., 65.]),\n",
       " array([55., 60., 62., 64., 65.]),\n",
       " array([55., 60., 62., 64., 65., 67.]),\n",
       " array([55., 57., 59., 60., 62., 64., 65.]),\n",
       " array([55., 59., 60., 62., 64., 65., 67.]),\n",
       " array([55., 60., 62., 65., 67.]),\n",
       " array([60., 62., 65., 67.]),\n",
       " array([60., 65., 67.]),\n",
       " array([60., 67.]),\n",
       " array([60., 62., 67.]),\n",
       " array([55., 60., 62., 67., 69.]),\n",
       " array([55., 60., 62., 64., 67.]),\n",
       " array([60., 62., 64., 67.]),\n",
       " array([55., 60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69.]),\n",
       " array([55., 57., 60., 62., 64., 67.]),\n",
       " array([67., 69., 72.]),\n",
       " array([67., 69., 72.]),\n",
       " array([67., 69., 72., 74.]),\n",
       " array([60., 67., 69., 72., 74., 76.]),\n",
       " array([67., 72., 74., 76.]),\n",
       " array([67., 69., 72.]),\n",
       " array([67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76.]),\n",
       " array([60., 62., 64., 67., 69., 72., 76.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([62., 64., 67., 69., 72., 74., 76.]),\n",
       " array([62., 69., 72., 74.]),\n",
       " array([69., 72.]),\n",
       " array([69., 72.]),\n",
       " array([60., 64., 65., 69., 72.]),\n",
       " array([60., 64., 65., 69., 72.]),\n",
       " array([60., 64., 65., 72.]),\n",
       " array([60., 65., 72.]),\n",
       " array([60., 65., 72.]),\n",
       " array([60., 65., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([67., 72., 74.]),\n",
       " array([60., 67., 72., 74.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 65., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76.]),\n",
       " array([60., 64., 65., 67., 69., 72., 74., 76.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([62., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 65., 67., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76.]),\n",
       " array([60., 62., 64., 67., 69., 72., 76.]),\n",
       " array([60., 62., 64., 69.]),\n",
       " array([67., 72.]),\n",
       " array([60., 62., 64., 65., 69., 72.]),\n",
       " array([60., 64., 65., 69., 72.]),\n",
       " array([60., 64., 65., 69., 72.]),\n",
       " array([60., 64., 65., 67., 69., 72., 76.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 81., 84.]),\n",
       " array([60., 64., 72., 76., 81., 84.]),\n",
       " array([60., 72.]),\n",
       " array([67., 72.]),\n",
       " array([60., 67., 72., 76., 79.]),\n",
       " array([60., 62., 64., 67., 72., 76., 84.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 84., 86.]),\n",
       " array([60., 84., 86.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 69., 72., 76.]),\n",
       " array([60., 69., 72., 76., 81.]),\n",
       " array([60., 69., 72., 76., 81.]),\n",
       " array([60., 69., 72., 76., 77., 81.]),\n",
       " array([60., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 65., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 72., 76., 77., 81., 84.]),\n",
       " array([60., 64., 65., 67., 72., 74., 76., 77., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 76., 77., 79., 84.]),\n",
       " array([60., 65., 67., 72., 77., 79., 84.]),\n",
       " array([60., 65., 67., 72., 77., 79., 84.]),\n",
       " array([60., 65., 67., 72., 77., 79., 84.]),\n",
       " array([60., 65., 67., 72., 77., 79.]),\n",
       " array([55., 60., 62., 65., 67., 72., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 74., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([60., 67., 72., 77., 79., 84.]),\n",
       " array([60., 67., 72., 77., 79., 84.]),\n",
       " array([60., 67., 72., 77., 79., 84., 91.]),\n",
       " array([60., 67., 72., 77., 79., 84., 86., 91.]),\n",
       " array([60., 67., 72., 79., 84., 86., 88., 91.]),\n",
       " array([72., 79., 84., 88., 91.]),\n",
       " array([67., 72., 74., 77., 79., 84., 86.]),\n",
       " array([67., 72., 74., 77., 79., 84., 86.]),\n",
       " array([67., 72., 77., 79., 84., 91.]),\n",
       " array([67., 72., 77., 79., 84.]),\n",
       " array([67., 72., 77., 79., 84.]),\n",
       " array([67., 72., 77., 79., 84.]),\n",
       " array([67., 72., 77., 79., 84.]),\n",
       " array([67., 72., 77., 79., 82., 84.]),\n",
       " array([77., 79., 82., 84., 91.]),\n",
       " array([79., 82., 84., 91.]),\n",
       " array([79., 82., 84., 91.]),\n",
       " array([67., 79., 84.]),\n",
       " array([67., 72.]),\n",
       " array([60., 62., 65.]),\n",
       " array([65., 67., 72.]),\n",
       " array([60., 67., 72., 74., 77.]),\n",
       " array([60., 67., 72., 74., 76., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 76., 79., 84.]),\n",
       " array([60., 62., 72., 76., 84.]),\n",
       " array([60., 64., 72., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 84., 86., 88.]),\n",
       " array([84., 86., 88., 91.]),\n",
       " array([84., 86., 88., 91.]),\n",
       " array([60., 67.]),\n",
       " array([67., 79.]),\n",
       " array([67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79.]),\n",
       " array([60., 62., 65., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 67., 72., 76., 79., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 79., 84., 86., 88.]),\n",
       " array([60., 67., 72., 84., 86., 88.]),\n",
       " array([60., 84., 86., 88., 91.]),\n",
       " array([60., 84., 86., 88., 91.]),\n",
       " array([60., 67., 84., 86., 88., 91.]),\n",
       " array([60., 67., 84., 86., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 84., 88., 91.]),\n",
       " array([60., 72., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 89., 91.]),\n",
       " array([60., 72., 79., 81., 84., 88., 91.]),\n",
       " array([60., 72., 79., 81., 84., 88., 91.]),\n",
       " array([60., 72., 81., 84., 88., 91.]),\n",
       " array([60., 72., 81., 84., 88., 91.]),\n",
       " array([60., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 79., 81., 84., 88., 89., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([55., 60., 67., 72., 79., 82., 84., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 91.]),\n",
       " array([60., 67., 72., 79., 84., 91.]),\n",
       " array([60., 62., 67., 72., 79., 84., 91.]),\n",
       " array([60., 62., 67., 72., 79., 84., 91.]),\n",
       " array([60., 62., 64., 67., 72., 84.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 74., 76., 81., 83., 84.]),\n",
       " array([60., 64., 67., 72., 74., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 81., 84.]),\n",
       " array([64., 67., 72., 76., 79., 81., 84.]),\n",
       " array([64., 67., 72., 76., 79., 81., 84.]),\n",
       " array([64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([64., 69., 76., 79., 81., 84.]),\n",
       " array([64., 69., 76., 79., 81., 84.]),\n",
       " array([64., 69., 76., 79., 81., 84., 88.]),\n",
       " array([64., 69., 76., 79., 81., 84., 88.]),\n",
       " array([64., 69., 71., 76., 79., 81., 84., 88.]),\n",
       " array([64., 69., 71., 76., 79., 81., 84., 88.]),\n",
       " array([64., 69., 71., 76., 79., 81., 84., 88.]),\n",
       " array([64., 69., 71., 76., 79., 81., 84., 88.]),\n",
       " array([62., 64., 69., 71., 76., 79., 81., 84., 88., 89.]),\n",
       " array([62., 64., 69., 71., 76., 79., 81., 84., 88., 89.]),\n",
       " array([62., 64., 69., 71., 76., 79., 81., 84., 88., 89., 91.]),\n",
       " array([62., 64., 69., 71., 76., 79., 81., 84., 88., 89.]),\n",
       " array([62., 64., 69., 71., 76., 79., 81., 84., 88., 89., 91.]),\n",
       " array([62., 64., 67., 69., 71., 76., 79., 81., 84., 88., 89.]),\n",
       " array([60., 64., 67., 69., 71., 72., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 71., 72., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 69., 72., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 72.]),\n",
       " array([67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 62., 81., 84.]),\n",
       " array([60., 62., 81., 84.]),\n",
       " array([60., 62., 81., 84.]),\n",
       " array([60., 62., 81., 84.]),\n",
       " array([60., 62., 64., 81., 84.]),\n",
       " array([60., 62., 81., 84.]),\n",
       " array([81., 84.]),\n",
       " array([81., 84.]),\n",
       " array([60., 64., 81.]),\n",
       " array([60., 64., 81.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 72., 81., 84., 88.]),\n",
       " array([72., 81., 84., 88.]),\n",
       " array([72., 79., 81., 84., 88.]),\n",
       " array([72., 79., 81., 84., 88.]),\n",
       " array([72., 79., 81., 84., 88.]),\n",
       " array([72., 79., 81., 84., 88.]),\n",
       " array([60., 72., 79., 81., 84., 88., 89.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([60., 72., 79., 81., 84., 88.]),\n",
       " array([60., 72., 79., 81., 84., 88.]),\n",
       " array([60., 62., 67., 72., 77., 79., 81., 84., 88., 89.]),\n",
       " array([60., 62., 72., 77., 79., 81., 84., 89.]),\n",
       " array([60., 62., 67., 72., 77., 79., 81., 84., 89.]),\n",
       " array([60., 62., 67., 72., 77., 79., 81., 84., 89.]),\n",
       " array([60., 62., 67., 72., 77., 79., 81., 84., 89.]),\n",
       " array([60., 62., 63., 67., 72., 77., 81., 82., 84., 91.]),\n",
       " array([60., 67., 72., 77., 81., 82., 84.]),\n",
       " array([60., 63., 67., 77., 81., 82.]),\n",
       " array([60., 62., 77., 81., 82.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 72., 81., 82., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 67., 72., 77., 79., 81., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 77., 79., 81., 84.]),\n",
       " array([60., 62., 72., 77., 79., 81., 84.]),\n",
       " array([60., 67., 72., 77., 79., 81.]),\n",
       " array([60., 72.]),\n",
       " array([60., 67., 72., 77.]),\n",
       " array([60., 67., 72., 76., 77., 79.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 84., 86., 88.]),\n",
       " array([60., 72., 84., 86., 88.]),\n",
       " array([60., 67., 72., 84., 86., 88.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 67., 72., 79., 84., 88.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([81., 84.]),\n",
       " array([60., 81., 84.]),\n",
       " array([79., 84.]),\n",
       " array([60., 67., 79., 81., 84.]),\n",
       " array([79., 81., 84.]),\n",
       " array([60., 67., 72., 77., 79., 81., 84.]),\n",
       " array([60., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 69., 72., 77., 79., 81., 84.]),\n",
       " array([60., 69., 72., 81., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 67., 69., 72., 81., 84.]),\n",
       " array([69., 72., 79., 81., 84.]),\n",
       " array([62., 67., 69., 72., 77., 79., 81., 84.]),\n",
       " array([62., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([62., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([62., 64., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 62., 64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([72., 76., 81., 84.]),\n",
       " array([60., 72., 81.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 72., 81.]),\n",
       " array([60., 67., 72., 81.]),\n",
       " array([67., 79., 81.]),\n",
       " array([67., 77., 79., 81.]),\n",
       " array([67., 74., 79., 81.]),\n",
       " array([62., 67., 74., 79., 81.]),\n",
       " array([62., 67., 74., 79., 81.]),\n",
       " array([62., 67., 74., 79., 81.]),\n",
       " array([62., 74., 79., 81.]),\n",
       " array([62., 74., 79., 81.]),\n",
       " array([62., 74., 79., 81.]),\n",
       " array([62., 79., 81.]),\n",
       " array([62., 69., 81.]),\n",
       " array([57., 62., 64., 69., 78., 81.]),\n",
       " array([62., 64., 67., 69., 78., 79., 81.]),\n",
       " array([50., 62., 64., 66., 67., 69., 76., 78., 79., 81., 83.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83., 86.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83., 86.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83., 86.]),\n",
       " array([62., 64., 67., 69., 76., 78., 81., 83., 86.]),\n",
       " array([62., 64., 67., 69., 72., 76., 78., 81.]),\n",
       " array([57., 60., 62., 64., 67., 69., 72., 76., 78., 79., 81., 84.]),\n",
       " array([57., 60., 61., 62., 64., 66., 67., 69., 72., 76., 78., 79., 81.,\n",
       "        84.]),\n",
       " array([57., 60., 61., 62., 64., 66., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([57., 60., 61., 62., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 69., 72., 81.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 69., 72., 81.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([67., 72., 81.]),\n",
       " array([60., 84.]),\n",
       " array([60., 84.]),\n",
       " array([60., 72., 81., 84.]),\n",
       " array([60., 67., 72., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 76., 79., 81., 84.]),\n",
       " array([60., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([72., 76., 77., 79., 81., 84.]),\n",
       " array([72., 76., 79., 84.]),\n",
       " array([72., 76., 79., 81., 84.]),\n",
       " array([72., 74., 76., 79., 81., 84., 88.]),\n",
       " array([72., 76., 79., 81., 84.]),\n",
       " array([72., 79., 81., 84.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([79., 81., 84.]),\n",
       " array([79., 81., 84.]),\n",
       " array([60., 72., 79., 81., 84.]),\n",
       " array([72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([67., 72., 79., 81.]),\n",
       " array([67., 72., 79., 81.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([72., 79., 81., 84.]),\n",
       " array([60., 67., 72., 79., 81., 84.]),\n",
       " array([79., 81.]),\n",
       " array([81., 84.]),\n",
       " array([81., 84.]),\n",
       " array([76., 81., 84.]),\n",
       " array([60., 76., 81., 84.]),\n",
       " array([60., 69., 81., 84.]),\n",
       " array([60., 69., 81., 84.]),\n",
       " array([60., 69., 81., 84.]),\n",
       " array([60., 81.]),\n",
       " array([60., 81.]),\n",
       " array([60., 64., 81., 84.]),\n",
       " array([60., 62., 64., 67., 79., 81., 84., 86., 88.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 86., 88., 91.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 86., 88., 89., 91.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 86., 88., 89., 91.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 86., 88., 91.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 86., 88., 89., 91.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79., 81., 84., 88., 89., 91.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79., 84., 88., 89., 91.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79., 84., 88., 89., 91.]),\n",
       " array([60., 62., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 84., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 91.]),\n",
       " array([60., 67., 72., 84., 91.]),\n",
       " array([60., 72., 84., 91.]),\n",
       " array([60., 67., 79., 82., 84., 91.]),\n",
       " array([67., 79., 84., 86., 89., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 91.]),\n",
       " array([60., 67., 79., 84., 86., 88., 91.]),\n",
       " array([60., 67., 79., 84., 86., 89., 91.]),\n",
       " array([60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 77., 79., 84.]),\n",
       " array([55., 60., 62., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([55., 60., 62., 67., 72., 74., 77., 79., 81., 84.]),\n",
       " array([55., 60., 62., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([55., 60., 62., 65., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 77., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 77., 81., 84.]),\n",
       " array([60., 62., 67., 72., 74., 84.]),\n",
       " array([60., 62., 67., 72., 74., 84.]),\n",
       " array([60., 62., 67., 72., 74.]),\n",
       " array([62., 67., 72., 74.]),\n",
       " array([62., 64., 67., 72., 74.]),\n",
       " array([62., 64., 67., 72., 74.]),\n",
       " array([62., 64., 67., 72.]),\n",
       " array([64., 67., 72.]),\n",
       " array([64., 67., 72.]),\n",
       " array([64., 67., 72.]),\n",
       " array([64., 67., 72.]),\n",
       " array([64., 74.]),\n",
       " array([64., 69.]),\n",
       " array([60., 64., 69., 72., 81.]),\n",
       " array([69., 81.]),\n",
       " array([64., 81.]),\n",
       " array([69., 81., 84.]),\n",
       " array([84., 88.]),\n",
       " array([84., 88.]),\n",
       " array([60., 67., 81.]),\n",
       " array([67., 79.]),\n",
       " array([67., 79.]),\n",
       " array([60., 67., 81., 84.]),\n",
       " array([60., 64., 69., 81.]),\n",
       " array([60., 64., 69., 76., 81., 84.]),\n",
       " array([64., 69., 81.]),\n",
       " array([60., 64., 69., 76., 81., 84.]),\n",
       " array([60., 64., 69., 76., 81., 84.]),\n",
       " array([57., 60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([57., 60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 69., 72., 76., 81., 84.]),\n",
       " array([64., 69., 72., 76., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([72., 76., 81., 84.]),\n",
       " array([81., 84.]),\n",
       " array([60., 64., 81., 84., 86.]),\n",
       " array([60., 81., 84.]),\n",
       " array([60., 81., 84., 88.]),\n",
       " array([60., 81., 84., 88.]),\n",
       " array([60., 64., 81., 84., 88.]),\n",
       " array([60., 62., 64., 79., 81., 84., 88., 91.]),\n",
       " array([60., 62., 64., 72., 79., 81., 84., 88., 91.]),\n",
       " array([60., 62., 64., 67., 72., 79., 81., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 81., 84., 88.]),\n",
       " array([67., 79., 81., 84.]),\n",
       " array([76., 79., 81., 84.]),\n",
       " array([64., 67., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81.]),\n",
       " array([67., 69., 71., 72., 76., 77., 79., 81.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([67., 69., 71., 72., 76., 77., 79., 81.]),\n",
       " array([60., 64., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([69., 72., 81., 84.]),\n",
       " array([69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81.]),\n",
       " array([67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 67., 69., 72., 76., 77., 79.]),\n",
       " array([60., 65., 67., 69., 72., 76., 77., 79.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([55., 60., 62., 65., 67., 72.]),\n",
       " array([55., 60., 62., 65., 67., 72.]),\n",
       " array([48., 55., 60., 62., 64., 65., 67., 72.]),\n",
       " array([48., 55., 60., 62., 64., 65., 67., 72.]),\n",
       " array([48., 55., 60., 62., 65., 67., 72., 79.]),\n",
       " array([60., 62., 65., 67., 72., 74., 77., 79., 84.]),\n",
       " array([60., 62., 67., 72., 74., 77., 79., 84.]),\n",
       " array([60., 62., 65., 67., 72., 74., 77., 84.]),\n",
       " array([60., 62.]),\n",
       " array([60., 62., 84.]),\n",
       " array([67., 72., 84.]),\n",
       " array([60., 67., 72., 74., 76.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([55., 60., 67., 72.]),\n",
       " array([48., 55., 60., 64., 67., 72.]),\n",
       " array([48., 55., 60., 64., 67., 72.]),\n",
       " array([48., 55., 60., 64., 67., 72.]),\n",
       " array([48., 55., 60., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([62., 64., 67., 69., 72.]),\n",
       " array([62., 64., 67., 69., 72.]),\n",
       " array([62., 64., 67., 69., 72.]),\n",
       " array([55., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69.]),\n",
       " array([60., 62., 64., 67., 69.]),\n",
       " array([57., 60., 62., 64., 67., 69.]),\n",
       " array([57., 60., 62., 64., 67., 69.]),\n",
       " array([57., 60., 62., 64., 67., 69.]),\n",
       " array([57., 62., 64., 67., 69.]),\n",
       " array([57., 60., 62., 64., 67., 69., 71., 72.]),\n",
       " array([57., 60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 62., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 62., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 62., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([64., 67., 72., 76.]),\n",
       " array([69., 72., 76.]),\n",
       " array([64., 72., 76.]),\n",
       " array([64., 72., 76.]),\n",
       " array([64., 69., 71., 72., 76.]),\n",
       " array([64., 69., 71., 72., 76.]),\n",
       " array([64., 67., 69., 71., 72., 74.]),\n",
       " array([62., 67., 69., 71., 72.]),\n",
       " array([62., 67., 69., 71., 72.]),\n",
       " array([60., 64., 67., 69., 72., 76.]),\n",
       " array([67., 69., 72.]),\n",
       " array([67., 69., 71., 72.]),\n",
       " array([67., 69., 71., 72.]),\n",
       " array([62., 67., 69., 71., 72.]),\n",
       " array([67., 69., 72.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 79.]),\n",
       " array([60., 62., 64., 67., 69., 72., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([67., 72.]),\n",
       " array([62., 67., 69., 72.]),\n",
       " array([67., 72., 76.]),\n",
       " array([84., 86.]),\n",
       " array([84., 86., 88.]),\n",
       " array([84., 88.]),\n",
       " array([67., 79., 84., 86., 88., 91.]),\n",
       " array([67., 72., 79., 84., 88., 91.]),\n",
       " array([67., 72., 79., 84., 88., 91.]),\n",
       " array([67., 79., 83., 84., 88., 91.]),\n",
       " array([67., 79., 83., 84., 86., 88., 91.]),\n",
       " array([67., 79., 83., 84., 86., 88., 91.]),\n",
       " array([67., 79., 83., 84., 86., 88.]),\n",
       " array([67., 79., 84., 86.]),\n",
       " array([67., 79., 84.]),\n",
       " array([67., 77., 79.]),\n",
       " array([67., 77., 79.]),\n",
       " array([77., 79.]),\n",
       " array([77., 79.]),\n",
       " array([79., 81., 84.]),\n",
       " array([60., 67., 72., 77., 79.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([65., 67.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 64., 65., 67.]),\n",
       " array([60., 64., 67., 72.]),\n",
       " array([67., 72.]),\n",
       " array([67., 69., 72.]),\n",
       " array([67., 72., 79., 84.]),\n",
       " array([67., 84., 86.]),\n",
       " array([67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72.]),\n",
       " array([60., 62., 64., 67., 69., 72., 76.]),\n",
       " array([67., 69., 72., 76.]),\n",
       " array([62., 67., 69., 72.]),\n",
       " array([69., 72., 76., 79.]),\n",
       " array([72., 84.]),\n",
       " array([67., 84.]),\n",
       " array([60., 62., 64., 67., 84.]),\n",
       " array([60., 62., 64., 67., 72., 84.]),\n",
       " array([60., 64., 67., 84.]),\n",
       " array([60., 64., 84.]),\n",
       " array([60., 64., 72., 84., 86.]),\n",
       " array([60., 64., 84., 86.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 67., 84.]),\n",
       " array([60., 84.]),\n",
       " array([60., 84.]),\n",
       " array([60., 84.]),\n",
       " array([60., 84., 88.]),\n",
       " array([60., 84.]),\n",
       " array([60., 64., 67., 72., 81., 84.]),\n",
       " array([60., 64., 67., 72., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72.]),\n",
       " array([60., 64., 67., 72., 79., 84.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 64., 67., 72., 79., 84., 88.]),\n",
       " array([60., 64., 67., 72., 79., 84., 88.]),\n",
       " array([60., 67., 72., 79., 84., 88.]),\n",
       " array([60., 64., 67., 72., 77., 79., 84., 88.]),\n",
       " array([60., 64., 67., 72., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 83., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 83., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 74., 76., 77., 79., 81., 84.]),\n",
       " array([57., 60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([57., 60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([57., 60., 62., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([57., 60., 62., 64., 67., 69., 71., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 71., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 71., 72., 76., 79., 81., 83., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84., 88.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 77., 79., 81., 84.]),\n",
       " array([60., 64., 67., 69., 72., 76., 81., 84.]),\n",
       " array([60., 62., 64., 67., 69., 72., 76., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([55., 60., 62., 64., 67., 72., 74., 76., 79., 84.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([48., 60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([48., 60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 79.]),\n",
       " array([60., 64., 67., 72., 79.]),\n",
       " array([55., 60., 64., 67., 72., 76., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([55., 60., 62., 64., 67., 72., 79.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76.]),\n",
       " array([60., 64., 67., 72., 76., 79.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 72.]),\n",
       " array([72., 76.]),\n",
       " array([60., 72., 84.]),\n",
       " array([60., 67., 72., 77., 84.]),\n",
       " array([60., 64., 67., 72., 76., 84.]),\n",
       " array([60., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 77., 79., 84.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 67., 72., 76., 79., 84.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 62., 64., 65., 67., 72., 84.]),\n",
       " array([60., 64., 67., 72., 84.]),\n",
       " array([60., 62., 64., 67., 72., 74., 76., 84.]),\n",
       " array([60., 62., 64., 65., 67., 72., 74., 76., 79., 84.]),\n",
       " array([60., 62., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 67., 72., 76., 84.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 62., 64., 65., 67., 72.]),\n",
       " array([60., 62., 64., 65., 67., 72.]),\n",
       " array([60., 62., 65., 67., 72.]),\n",
       " array([60., 64., 65., 67., 72.]),\n",
       " array([60., 65., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72.]),\n",
       " array([60., 67., 72., 79.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 67., 72., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 72., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 72., 79., 84., 86., 88., 89., 91.]),\n",
       " array([60., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 79., 82., 84., 86., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([60., 67., 72., 79., 82., 84., 86., 87., 88., 89., 91.]),\n",
       " array([57., 60., 67., 72., 77., 79., 81., 82., 83., 84., 86., 87., 88.,\n",
       "        89., 91.]),\n",
       " array([50., 57., 60., 67., 72., 77., 79., 81., 82., 83., 84., 86., 87.,\n",
       "        88., 89., 91.]),\n",
       " array([50., 57., 60., 67., 72., 77., 79., 81., 82., 83., 84., 86., 87.,\n",
       "        88., 89., 91.]),\n",
       " array([50., 57., 60., 64., 67., 72., 77., 79., 81., 82., 83., 84., 86.,\n",
       "        87., 88., 89., 91.]),\n",
       " array([50., 57., 60., 64., 67., 72., 77., 79., 81., 82., 83., 84., 86.,\n",
       "        87., 88., 89., 91.]),\n",
       " array([50., 57., 60., 64., 67., 72., 77., 79., 81., 82., 83., 84., 86.,\n",
       "        87., 88., 89., 91.]),\n",
       " array([50., 57., 60., 63., 64., 67., 72., 77., 79., 81., 83., 84., 86.,\n",
       "        87., 88., 89., 91.]),\n",
       " array([50., 57., 60., 63., 64., 67., 70., 72., 77., 79., 81., 83., 84.,\n",
       "        86., 87., 88., 89., 91.]),\n",
       " array([50., 51., 57., 60., 63., 64., 67., 70., 72., 77., 79., 80., 81.,\n",
       "        83., 84., 86., 87., 88., 89., 91.]),\n",
       " array([50., 51., 55., 57., 60., 63., 64., 67., 70., 72., 77., 79., 80.,\n",
       "        81., 83., 84., 86., 87., 88., 89., 91.]),\n",
       " array([42., 43., 50., 51., 52., 54., 55., 57., 60., 63., 64., 67., 70.,\n",
       "        72., 76., 77., 79., 80., 81., 83., 84., 86., 87., 88., 89., 90.,\n",
       "        91.]),\n",
       " array([43., 54., 55., 57., 60., 62., 64., 67., 70., 72., 74., 76., 77.,\n",
       "        79., 81., 83., 84., 86., 88., 89., 91.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79., 81., 84., 86., 91.]),\n",
       " array([55., 60., 62., 64., 67., 72., 76., 79., 81., 84.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67., 72.]),\n",
       " array([60., 64., 67., 72., 76., 79., 84.]),\n",
       " array([60., 64., 72., 84.]),\n",
       " array([60., 64., 67., 72., 79., 84., 86., 88., 91.]),\n",
       " array([60., 64., 67., 72., 79., 84., 88., 91.]),\n",
       " array([60., 64., 67., 72., 84., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 67., 79., 84., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 67., 84., 88., 91.]),\n",
       " array([60., 67., 79., 84., 88., 91.]),\n",
       " array([60., 67., 79., 84., 88., 91.]),\n",
       " array([60., 67., 79., 84., 88., 91.]),\n",
       " array([60., 67., 72., 79., 84., 86., 88., 89., 91.]),\n",
       " array([57., 60., 64., 67., 72., 79., 81., 83., 84., 86., 88., 89., 91.]),\n",
       " array([43., 50., 57., 60., 64., 67., 72., 79., 81., 83., 84., 86., 88.,\n",
       "        89., 91.]),\n",
       " array([50., 57., 60., 64., 67., 72., 81., 83., 84., 86., 88., 89., 91.]),\n",
       " array([57., 60., 64., 67., 72., 81., 84., 88., 89., 91.]),\n",
       " array([60., 62., 64., 67., 69.]),\n",
       " array([60., 62., 67.]),\n",
       " array([60., 64., 67., 72., 79.]),\n",
       " array([60., 64., 84., 88., 91.]),\n",
       " array([60., 64., 84., 88., 91.]),\n",
       " array([60., 64., 67., 72.]),\n",
       " array([60., 62., 64., 67.]),\n",
       " array([60., 67.]),\n",
       " array([60., 67., 72., 79.]),\n",
       " array([60., 84.]),\n",
       " array([60., 84.]),\n",
       " ...]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка сгенерированных музыкальных последовательностей из файла\n",
    "with open('/kaggle/working/Testpred_majority0.3.pickle', 'rb') as f:\n",
    "    r = pickle.load(f)\n",
    "filtered_sublists = [sublist for sublist in r if len(sublist) >= 2]\n",
    "filtered_sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T03:13:55.829423Z",
     "iopub.status.busy": "2023-06-14T03:13:55.828697Z",
     "iopub.status.idle": "2023-06-14T03:15:12.179293Z",
     "shell.execute_reply": "2023-06-14T03:15:12.177471Z",
     "shell.execute_reply.started": "2023-06-14T03:13:55.829368Z"
    }
   },
   "outputs": [],
   "source": [
    "# Перевод .pickle в аккорды и далее в .mid\n",
    "\n",
    "import mido\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "timestep_duration = 0.00000005\n",
    "ticks_per_beat = 80\n",
    "tempo = 500000\n",
    "note_duration_ticks = ticks_per_beat\n",
    "\n",
    "def load_predictions():\n",
    "    with open('/kaggle/working/Testpred_majority0.3.pickle', 'rb') as f:\n",
    "        predictions = pickle.load(f)\n",
    "    return predictions\n",
    "\n",
    "def tonnetz_to_midi(tonnetz_predictions):\n",
    "    midi_file = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    for timestep, pitch_out_batch in enumerate(tonnetz_predictions):\n",
    "        time = int(timestep * timestep_duration * ticks_per_beat)\n",
    "        if len(pitch_out_batch) > 0:\n",
    "            chord_notes = [int(pitch) for pitch in pitch_out_batch]\n",
    "\n",
    "            if len(chord_notes) > 0:\n",
    "                for note in chord_notes:\n",
    "                    note_on = mido.Message('note_on', note=note, velocity=64, time=time)\n",
    "                    track.append(note_on)\n",
    "\n",
    "                for note in chord_notes:\n",
    "                    note_off = mido.Message('note_off', note=note, velocity=64, time=time + note_duration_ticks)\n",
    "                    track.append(note_off)\n",
    "        else:\n",
    "            pause = mido.Message('note_off', note=0, velocity=0, time=time)\n",
    "            track.append(pause)\n",
    "\n",
    "    return midi_file\n",
    "\n",
    "tonnetz_predictions = load_predictions()\n",
    "midi_file = tonnetz_to_midi(tonnetz_predictions)\n",
    "output_path = '/kaggle/working/jazz_output_chords_80.mid'\n",
    "midi_file.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T03:20:04.261599Z",
     "iopub.status.busy": "2023-06-14T03:20:04.261052Z",
     "iopub.status.idle": "2023-06-14T03:21:16.655845Z",
     "shell.execute_reply": "2023-06-14T03:21:16.654462Z",
     "shell.execute_reply.started": "2023-06-14T03:20:04.261553Z"
    }
   },
   "outputs": [],
   "source": [
    "import mido\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "timestep_duration = 0.00000005\n",
    "ticks_per_beat = 80\n",
    "tempo = 500000\n",
    "note_duration_ticks = ticks_per_beat\n",
    "\n",
    "def load_predictions():\n",
    "    with open('/kaggle/working/Testpred_majority0.3.pickle', 'rb') as f:\n",
    "        predictions = pickle.load(f)\n",
    "    return predictions\n",
    "\n",
    "def remove_repeated_lists(predictions):\n",
    "    unique_predictions = []\n",
    "    count = 0\n",
    "    for prediction in predictions:\n",
    "        if unique_predictions and np.array_equal(unique_predictions[-1], prediction):\n",
    "            count += 1\n",
    "            if count < 3:\n",
    "                unique_predictions.append(prediction)\n",
    "        else:\n",
    "            count = 0\n",
    "            unique_predictions.append(prediction)\n",
    "    return unique_predictions\n",
    "\n",
    "def tonnetz_to_midi(tonnetz_predictions):\n",
    "    midi_file = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    for timestep, pitch_out_batch in enumerate(tonnetz_predictions):\n",
    "        time = int(timestep * timestep_duration * ticks_per_beat)\n",
    "        if len(pitch_out_batch) > 0:\n",
    "            chord_notes = [int(pitch) for pitch in pitch_out_batch]\n",
    "\n",
    "            if len(chord_notes) > 0:\n",
    "                for note in chord_notes:\n",
    "                    note_on = mido.Message('note_on', note=note, velocity=64, time=time)\n",
    "                    track.append(note_on)\n",
    "\n",
    "                for note in chord_notes:\n",
    "                    note_off = mido.Message('note_off', note=note, velocity=64, time=time + note_duration_ticks)\n",
    "                    track.append(note_off)\n",
    "        else:\n",
    "            pause = mido.Message('note_off', note=0, velocity=0, time=time)\n",
    "            track.append(pause)\n",
    "\n",
    "    return midi_file\n",
    "\n",
    "tonnetz_predictions = load_predictions()\n",
    "tonnetz_predictions_unique = remove_repeated_lists(tonnetz_predictions)\n",
    "midi_file = tonnetz_to_midi(tonnetz_predictions_unique)\n",
    "output_path = '/kaggle/working/jazz_output_chords_lessrep_80.mid'\n",
    "midi_file.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-14T15:36:32.592188Z",
     "iopub.status.busy": "2023-06-14T15:36:32.590372Z",
     "iopub.status.idle": "2023-06-14T15:36:47.128848Z",
     "shell.execute_reply": "2023-06-14T15:36:47.127043Z",
     "shell.execute_reply.started": "2023-06-14T15:36:32.592125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Варьировала тут настройки\n",
    "\n",
    "import mido\n",
    "import pickle\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "timestep_duration = 0.00000005\n",
    "ticks_per_beat = 75 # this one\n",
    "tempo = 500000\n",
    "note_duration_ticks = ticks_per_beat\n",
    "\n",
    "def load_predictions():\n",
    "    with open('/kaggle/working/Testpred_majority0.3.pickle', 'rb') as f:\n",
    "        predictions = pickle.load(f)\n",
    "    return predictions\n",
    "\n",
    "def remove_repeated_lists(predictions):\n",
    "    unique_predictions = []\n",
    "    count = 0\n",
    "    for prediction in predictions:\n",
    "        if unique_predictions and np.array_equal(unique_predictions[-1], prediction):\n",
    "            count += 1\n",
    "            if count < 2: # this one\n",
    "                unique_predictions.append(prediction)\n",
    "        else:\n",
    "            count = 0\n",
    "            unique_predictions.append(prediction)\n",
    "    return unique_predictions\n",
    "\n",
    "def tonnetz_to_midi(tonnetz_predictions):\n",
    "    midi_file = mido.MidiFile()\n",
    "    track = mido.MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    for timestep, pitch_out_batch in enumerate(tonnetz_predictions):\n",
    "        time = int(timestep * timestep_duration * ticks_per_beat)\n",
    "        if len(pitch_out_batch) > 0:\n",
    "            chord_notes = [int(pitch) for pitch in pitch_out_batch]\n",
    "\n",
    "            if len(chord_notes) > 0:\n",
    "                for note in chord_notes:\n",
    "                    note_on = mido.Message('note_on', note=note, velocity=64, time=time)\n",
    "                    track.append(note_on)\n",
    "\n",
    "                for note in chord_notes:\n",
    "                    note_off = mido.Message('note_off', note=note, velocity=64, time=time + note_duration_ticks)\n",
    "                    track.append(note_off)\n",
    "        else:\n",
    "            pause = mido.Message('note_off', note=0, velocity=0, time=time)\n",
    "            track.append(pause)\n",
    "\n",
    "    return midi_file\n",
    "#add some postprocess\n",
    "def process_midi_with_fluidsynth(midi_path, soundfont_path, output_path):\n",
    "    cmd = f'fluidsynth -T wav -F \"{output_path}\" \"{soundfont_path}\" \"{midi_path}\"'\n",
    "    subprocess.run(cmd, shell=True)\n",
    "\n",
    "# Загрузка предсказаний\n",
    "tonnetz_predictions = load_predictions()\n",
    "tonnetz_predictions_unique = remove_repeated_lists(tonnetz_predictions)\n",
    "\n",
    "# Создание MIDI-файла\n",
    "midi_file = tonnetz_to_midi(tonnetz_predictions_unique)\n",
    "output_midi_path = '/kaggle/working/jazz_output_chords_lessrep2FS_75.mid'\n",
    "midi_file.save(output_midi_path)\n",
    "\n",
    "# Указание пути к SoundFont файлу\n",
    "soundfont_path = './font.sf2' \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
